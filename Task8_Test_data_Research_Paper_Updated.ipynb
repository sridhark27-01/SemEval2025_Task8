{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d43ee9cb2d074223bb0a857a8a63b285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d8deda8951545e49b5a7d87158e6f4c",
              "IPY_MODEL_b6142b0557b74b23ad4e76b3f7fa08f7",
              "IPY_MODEL_cc4d6cab361a4fc1b0a3ca08b5dbbce9"
            ],
            "layout": "IPY_MODEL_ab0dd553b2164b97a6e245e0f275ca2f"
          }
        },
        "9d8deda8951545e49b5a7d87158e6f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70d40d2945fa443eb364cdfdb662c561",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd89f88fc784c84a40326f2dba4d047",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b6142b0557b74b23ad4e76b3f7fa08f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5083c3a200944d48fa281bcae819e05",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b198e778f294782868531b1320c9bad",
            "value": 48
          }
        },
        "cc4d6cab361a4fc1b0a3ca08b5dbbce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1e8fe7afb2f45afb9f386e96fd74572",
            "placeholder": "​",
            "style": "IPY_MODEL_56482cad62b44dea821d5bd0028d33c8",
            "value": " 48.0/48.0 [00:00&lt;00:00, 860B/s]"
          }
        },
        "ab0dd553b2164b97a6e245e0f275ca2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d40d2945fa443eb364cdfdb662c561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd89f88fc784c84a40326f2dba4d047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5083c3a200944d48fa281bcae819e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b198e778f294782868531b1320c9bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1e8fe7afb2f45afb9f386e96fd74572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56482cad62b44dea821d5bd0028d33c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "392691c2745643a985137f433684b39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_064657706c844c2f827c99d6ed12ce96",
              "IPY_MODEL_50203869064e420c98382d0667013be1",
              "IPY_MODEL_a75328fa4ba44ea799fc07d36aa5c32d"
            ],
            "layout": "IPY_MODEL_223bdb39e1ea421685ac6753bef0875c"
          }
        },
        "064657706c844c2f827c99d6ed12ce96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a247316b1e714cbea0d54e6d3e72f4e9",
            "placeholder": "​",
            "style": "IPY_MODEL_c432108993be4e408b56abb10e328699",
            "value": "vocab.txt: 100%"
          }
        },
        "50203869064e420c98382d0667013be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3508c62113545e99e2e14d07709c928",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3a49e26529e4f7bac6fccf08a97d7f1",
            "value": 231508
          }
        },
        "a75328fa4ba44ea799fc07d36aa5c32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_994db5a61f124919ad6c545ba4a0fbae",
            "placeholder": "​",
            "style": "IPY_MODEL_faa071cda7eb45fbb3ee8acc4d31c356",
            "value": " 232k/232k [00:00&lt;00:00, 2.89MB/s]"
          }
        },
        "223bdb39e1ea421685ac6753bef0875c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a247316b1e714cbea0d54e6d3e72f4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c432108993be4e408b56abb10e328699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3508c62113545e99e2e14d07709c928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a49e26529e4f7bac6fccf08a97d7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "994db5a61f124919ad6c545ba4a0fbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa071cda7eb45fbb3ee8acc4d31c356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc8090ea8194dbba2c9950aaadf3ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f510db135fdb4764836b54669f126bf8",
              "IPY_MODEL_d8f20eef06c745a396ff487bd5a671e1",
              "IPY_MODEL_bd2a58e209ce4ec8a014b3c3cf6ea743"
            ],
            "layout": "IPY_MODEL_6c667a128d8645ecb8e69d2040dc8a98"
          }
        },
        "f510db135fdb4764836b54669f126bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f874e42404426daadd4c290928ea9e",
            "placeholder": "​",
            "style": "IPY_MODEL_b12a8743cf2143d08f632cc46c0add8a",
            "value": "tokenizer.json: 100%"
          }
        },
        "d8f20eef06c745a396ff487bd5a671e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_137cc6a530d14433bcae0b727a5ee9f7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9804e11fabfd44ac812e0fa1e4ff39c8",
            "value": 466062
          }
        },
        "bd2a58e209ce4ec8a014b3c3cf6ea743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369bc5fec6e641e5807c9be2f03e29b6",
            "placeholder": "​",
            "style": "IPY_MODEL_f50a9526633e4c1c87739373f4ac7980",
            "value": " 466k/466k [00:00&lt;00:00, 3.47MB/s]"
          }
        },
        "6c667a128d8645ecb8e69d2040dc8a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f874e42404426daadd4c290928ea9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12a8743cf2143d08f632cc46c0add8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "137cc6a530d14433bcae0b727a5ee9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9804e11fabfd44ac812e0fa1e4ff39c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "369bc5fec6e641e5807c9be2f03e29b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50a9526633e4c1c87739373f4ac7980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b7410a73efe4986baba56df5f04e4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73c1982ca10a4f0ab8d8a50f2bc02450",
              "IPY_MODEL_5a500085c54443a680d9a1764a5e8f7f",
              "IPY_MODEL_5610979aafb143b4b464fd9c2856de6e"
            ],
            "layout": "IPY_MODEL_c6493d5854b847c49311c0bc01a81cb2"
          }
        },
        "73c1982ca10a4f0ab8d8a50f2bc02450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cda847b6f4e4b8ab19bb64db189303d",
            "placeholder": "​",
            "style": "IPY_MODEL_b792ecad6e5143b9aae374574720dc66",
            "value": "config.json: 100%"
          }
        },
        "5a500085c54443a680d9a1764a5e8f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe30a49a4024b89822736207479e1a6",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2b2a5d4fd014f21b154bf78b673df01",
            "value": 483
          }
        },
        "5610979aafb143b4b464fd9c2856de6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19907b18c334ef085d7f8560f143bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_258c22209fff4178b763b5a69cbfe41d",
            "value": " 483/483 [00:00&lt;00:00, 7.27kB/s]"
          }
        },
        "c6493d5854b847c49311c0bc01a81cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cda847b6f4e4b8ab19bb64db189303d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b792ecad6e5143b9aae374574720dc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfe30a49a4024b89822736207479e1a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b2a5d4fd014f21b154bf78b673df01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a19907b18c334ef085d7f8560f143bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258c22209fff4178b763b5a69cbfe41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c85d48b149c40bd85674aecf4ed8c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780b863d6109441691dba858593e89c0",
              "IPY_MODEL_c943b038d2ae4d7d9898a33c1b73cfab",
              "IPY_MODEL_01fa202b1b3f48d282e229688d905400"
            ],
            "layout": "IPY_MODEL_2a6c85c8cb4046a6975272af1504606b"
          }
        },
        "780b863d6109441691dba858593e89c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3738d75d6a3b45ff82639ac1ee468ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_5374361a506f49d5904f88a4c34041d8",
            "value": "model.safetensors: 100%"
          }
        },
        "c943b038d2ae4d7d9898a33c1b73cfab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc560723ea24331b49bacfada922d14",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75613268e02e482989581da9f8167140",
            "value": 267954768
          }
        },
        "01fa202b1b3f48d282e229688d905400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138c8aef60e149afa6291a2c7db81e22",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef365173f464fcbb6316e64495a338b",
            "value": " 268M/268M [00:01&lt;00:00, 229MB/s]"
          }
        },
        "2a6c85c8cb4046a6975272af1504606b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3738d75d6a3b45ff82639ac1ee468ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5374361a506f49d5904f88a4c34041d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc560723ea24331b49bacfada922d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75613268e02e482989581da9f8167140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "138c8aef60e149afa6291a2c7db81e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef365173f464fcbb6316e64495a338b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IDbijPxVHes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzF6Idc6VKCn",
        "outputId": "dce57fff-671d-43d9-84a7-75c9c8d216ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clx91GYqUZNh",
        "outputId": "a28c2927-32ca-44cc-cca7-7ed184608e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "question_answers=pd.read_csv(\"/content/drive/MyDrive/competition/competition/test_qa.csv\")\n",
        "print(question_answers.shape)\n",
        "print(question_answers.columns)\n",
        "grouped_counts = question_answers.groupby('dataset').size().reset_index(name='no of questions')\n",
        "\n",
        "# Display the grouped counts\n",
        "print(grouped_counts)"
      ],
      "metadata": {
        "id": "XTsTkvOiVZIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e11943-8e3e-43ab-d6ab-7048e23a9108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(522, 2)\n",
            "Index(['question', 'dataset'], dtype='object')\n",
            "                 dataset  no of questions\n",
            "0             066_IBM_HR               39\n",
            "1        067_TripAdvisor               29\n",
            "2   068_WorldBank_Awards               34\n",
            "3           069_Taxonomy               35\n",
            "4      070_OpenFoodFacts               29\n",
            "5                071_COL               36\n",
            "6         072_Admissions               39\n",
            "7           073_Med_Cost               32\n",
            "8               074_Lift               35\n",
            "9          075_Mortality               29\n",
            "10               076_NBA               36\n",
            "11       077_Gestational               31\n",
            "12             078_Fires               39\n",
            "13            079_Coffee               38\n",
            "14             080_Books               41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions=question_answers['question'].tolist()\n",
        "datasets=question_answers['dataset'].tolist()\n",
        "\n",
        "print(questions)\n",
        "print(len(set(datasets)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQVAzDhXjBR",
        "outputId": "80fd4c7d-2a2a-4e76-84a3-ea0050069c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Is our average employee older than 35?', 'Is the most frequent travel value rarely traveling?', 'Is the highest DailyRate equal to 1499?', 'Is the highest DailyRate negative?', 'Is our research dept bigger than sales?', 'Is the highest rating given to any performance to 4?', 'Are there more employees who travel frequently than those who work in the HR department?', 'Is the average MonthlyIncome of employees affected by attrition less than those not affected?', 'Is the standard number of working hours the same across all employees?', 'What is the most common role?', 'Which department has the highest average YearsAtCompany?', 'What is the least common marital status?', 'What is the most frequent field of education for our employees?', 'Which travel category has the highest average income?', ' Which gender is most satisfied with the job on average?', 'What is the most common score given work and life balance?', 'Which EducationField do we employ the least?', 'What is the average age of our employees?', 'What is the total number of different job roles offered by IBM?', 'What is the maximum years someone has been at IBM?', 'What is the median monthly income of our employees?', 'What is the sum of the miles employees have to travel to get to work?', 'What is the average number of total working years for employees who are working in sales?', 'How many employees rate their satisfaction with their environment with a score of 4?', 'What is the range (max - min) of YearsSinceLastPromotion?', 'What is the longest time someone has been without a promotion?', 'List the unique different grades received by anyone for their performance.', 'List the amounts of the lowest 5 monthly incomes.', 'List all the different education levels of our employees can be classified into.', 'List the top 5 highest PercentSalaryHike values. The answer is a list with five values, even if they are repeated.', 'List the 5 most common ages of our employees.', 'List the top 3 most common job roles our company has.', 'List the 2 departments that employ the most people.', 'List the different marital status values in our database.', 'List all the different (unique) values we use to classify the field of education of our employees.', 'List the top 5 BusinessTravel categories.', 'List all the unique possible values overtime can take.', 'List the 4 most common JobLevels.', 'List the 3 most common JobLevels.', 'Does the dataset contain any review that more than forty users have labeled as helpful?', 'Are all the reviews sources (phone or not phone) non-null?', 'Is 1 the least frequent overall rating given in a review?', 'How many reviews give ratings related to the location?', 'Is there more overall ratings given than ratings related to the location?', 'Is there any review written in 2024?', 'Are all of our reviews labelled helpful by someone?', 'Are there more reviews marked as being made from a phone than not?', 'Is the maximum number of helpful votes found in only one review?', 'Is the best possible review for room ratings found in more than fifteen reviews?', 'Which year had the highest number of reviews made?', 'What is the average rating given to rooms?', 'What (non-null) room rating is most common?', 'Which value is most frequent for num_helpful_votes`?', \"Who is the author of 'value with a view'?\", 'What is the average review length (in characters) without taking the title into account?', 'What is the total number of reviews?', 'What is the highest number of users that has labeled a single review as helpful?', 'What is the average number of helpful votes?', 'What is the length of the longest text of a review (in chars)?', 'What is the year of the first review made?', 'How many reviews did family fun guru write?', 'What is the sum of all helpful votes for these reviews?', 'List the top 4 years according to the number of reviews.', 'List the 5 (non-unique) highest values of `num_helpful_votes`.', 'List the usernames of the authors who provided a username and wrote more than 3 reviews. If there are none answer with an empty list.', 'List the usernames of the authors who provided a username and wrote more than 4 reviews. If there are none answer with an empty list.', 'List the 5 largest non-unique (they can be repeated) offering IDs.', 'List the 4 most common years a guest stayed at a property.', 'Does any entry in the dataset have a supplier contract greater than one million dollars?', 'Is there any region which was awarded only one contract?', 'Is India amongst the borrower countries?', 'Is India the borrower country with the most contracts awarded?', 'Is there any project where the review is made before its execution?', 'Is there any project where the review is made after its execution?', 'Is any supplier from the US?', 'What is the most frequent method of procurement for a given contract?', 'Which region has the most contracts?', 'What is the longest name amongst the countries which have borrowed money? ', 'What is the procurement category associated with the largest contract?', 'Which region has the largest contracts on average?', 'Who is the most frequent country of borrowers present in the dataset?', 'Which global project practice would appear first if we sorted the columnn from A to Z?', 'How big is the biggest contract in the dataset? Answer in USD.', 'How many different fiscal years the contracts belong to?', 'What is the total number of procurements in the dataset?', 'How big is the average procurement across all entries?', 'Assuming supplier IDs are assigned from lowest to highest, what is the ID of the oldest supplier present in the dataset?', 'What is the standard deviation of the contracts awarded?', 'What is the total number of supplier contracts in the 2024 fiscal year?', 'List the 3 quantities of usd associated with the top 3 biggest contracts.', 'Are there contracts awarded after the 2020 fiscal year had ended?', 'Assuming new suppliers get the last assigned id + 1, what are the unique IDs of the earliest 5 different suppliers we have in the dataset?', 'What are the 3 fiscal years that had the most procurements?', 'For each of the first three fiscal years present in this dataset list the total amount of dollars awarded.', 'List the amounts awarded to the 2 contracts that are strictly over 100k dollars but closest to 100,000USD.', ' How much were the 4 largest contracts in central and west africa awarded for? Answer with a list with one amount per contract', 'List the 5 countries which most frequently borrow money through a procurement.', 'List the 4 regions the countries most frequently belong to.', 'List the 4 most frequent methods of procurement.', \"What are the first 4 (row-wise) distinct 'Supplier Countries' we can find in the dataset?\", 'List the unique review methods for contracts awarded above five hundred thousand dollars', 'List the unique review methods for contracts awarded more than 500000USD', 'Is there a first tier category with a name related to attractions?', 'Are there more than five first tier categories?', 'Is any entry in the third tier a (direct or otherwise) descendant of 150?', 'Are all rows named?', 'Are there any fourth level entities in the taxonomy?', 'Are there more entities with a valid parent ID than third tier entities?', 'Does the dataset contain exactly 703 entries?', 'Do all entities have a valid unique value associated?', 'Which first tier category name has the most descendants? (direct or otherwise)', 'What is most common category name among the first level categories?', 'Which first tier category has the second largest amount of descendants (direct or otherwise)?', 'What is the second most popular category name among the first level categories?', 'What is the most common unique parent ID found in the dataset?', 'What is the non-null third level value in the dataset that appears first?', 'What is the name of the direct ascendant of the bars and restaurants entity?', 'How many elements are there in our taxonomy?', 'How many elements in the taxonomy do not have a parent id associated?', 'What is the total number of unique non-null Parent values?', 'How many entries belong to the third or fourth tiers?', 'How many unique entries exist in the first level of our taxonomy?', 'How many rows contain null values in Tier 2?', 'How many Parent IDs appear exactly once?', 'Are all names unique?', 'What is the number of unique names?', 'List the 3 Parent values associated the 3 highest number of descendants (direct or otherwise).', 'List the entry counts for the attractions and automotive entities.', 'List the number of children for the categories of commercial trucks and convertibles. Answer with a two element list.', 'List counts of non-null values for each Tier column.', 'List the first (by number of appearance) 3 different values in the highest tier of the dataset. If there are less than 3 list as many as there are.', 'List the first (by row number) 2 different level 1 values found in the dataset. If there are less than 2 list as many as there are.', 'List the first (by number of appearance) 4 different second highest level values.', 'List all (unique) highest tier values present in the first 4 rows.', 'List the 4 first tier values present in the first 4 rows.', 'List the first 4 different non-null parent values found in the dataset. If there are less than 4 list as many as there are.', 'List the first 3 different non-null parent values found in the dataset. If there are less than 3 list as many as there are.', 'Is there any vegan product in our dataset?', 'Did Eduardo create upload any products to the database?', 'Is the product with code 00001522 apt for vegans?', 'Is any product palm oil free?', \"Are there any products belonging to the category 'Plant-based foods and beverages'?\", 'Are all products created by the openfoodfacts contributors labeled as vegan?', ' Are more than a 1000 products sold in Mercadona stores?', \"Are there products from the 'Hacendado' brand in more than one country?\", 'What is the most frequent brand name? Answer with a single category.', 'Which country has the most products listed? Answer with a single category.', 'What is the single label associated with the most products? Answer with a single category.', \"How many products are labeled as 'Vegan'?\", 'Which store has the most products listed?', 'Which creator has contributed the most to the database?', \"How many products belong to the 'Hacendado' brand?\", 'How many unique countries exist in the dataset?', 'How many products have no labels?', \"How many products are associated with the 'Mercadona' type of store?\", 'What is the total number of products in the dataset that have a non-empty product name?', 'What is the total number of products in the dataset that have a unique product code?', \"How many products are listed under 'Plant-based foods and beverages'?\", ' List the product codes associated with the Seitan category', ' List the product names associated with the Seitan category', 'List the two most frequent labels in the dataset', ' \"List the five most frequent labels in the dataset. If there are less than five list as many as there are.\"', ' List the two most frequent store names in the dataset', ' List the two number of stores for the two most frequent store names in the dataset', ' List the 3 most frequent countries in the dataset', ' List the 3 number of products present for the 3 most frequent countries in the dataset', 'Is Switzerland the country with the highest Cost of Living Index?', 'Is the Bahamas ranked second in the dataset?', 'Is there any country with a Rent Index above 65?', 'Does Iceland have more purchasing power than a country that has a 100 in that index?', 'Is Barbados considered overall more expensive than the country ranked in the 10th place?', 'Does the dataset include at least 120 countries?', 'If I am from Iceland and I move to Singapore, would I expect my rent to be more expensive according to the index?', 'Is Switzerland considered to be the most expensive country regardless if I rent or own my home?', 'Which country ranks the most expensive in terms of overall cost of living?', 'In which country would it be cheaper to buy groceries?', 'If I have to rent but I want to move to the cheapest country to live in, where should I move to?', 'In which country would it be most expensive to eat in a restaurant?', 'Which country has the second-highest world rent?', 'Which country is the second most expensive destination to move to considering I am not a home owner in the country?', 'Which country has a Groceries Index closest to 80?', 'What is the Cost of Living Index assigned to the most expensive country to live in?', 'What is the Rent Index of the top-ranked country?', 'What is the total number of countries in the dataset?', 'What is the average Groceries Index across all countries?', 'What is the difference between the highest and lowest Restaurant Price Index?', \"If I'm moving to Singapore and I have to rent there, what would my associated index for cost of living be?\", 'What is the mean Local Purchasing Power Index of the top 10 countries by rank?', \"What is Iceland's rank?\", 'List the Rent Index values of the top 5 overall most expensive countries excluding rent.', 'List the Cost of Living Index values of the 5 countries that are ranked the cheapest.', 'List the Local Purchasing Power Index values of countries ranked 1st to 5th.', 'List the 3 associated index values for the countries where groceries are most expensive.', 'List the index given to restaurant prices for the top 5 overall most expensive countries for home owners.', 'List the 5 lowest indices for cost of life for a person who have to rent.', 'List the 5 Local Purchasing Power Index values closest to 100.', 'List the names of the top 5 ranked countries.', 'List the 3 countries where I would pay the most for groceries.', \"List the 3 countries where it's cheapest to rent.\", 'List the countries ranked 10th to 15th.', 'List the top 5 countries by Local Purchasing Power Index.', 'List the 3 countries where restaurants are the cheapest.', 'Is there any applicant who got a grade better than 330 in their graduate record examination?', 'Is there any applicant who got a score worse than 100 in their English test?', 'Is the best CGPA greater than 9.5?', 'Did any applicant with a perfect university rating score get a grade below 320 in their graduate record examination?', 'Is there an applicant with a chance above 95 per cent of getting into the university they applied to?', \"Is the lowest score assigned to a student's stated purpose for admission worse than 2?\", \"Are there any applicants who don't have any research experience previous to their application?\", 'Is the average English score better than 105?', 'What is the rating given by the college they applied to to the applicant with the highest CGPA?', 'What is the university rating of the applicant with the lowest GRE score?', 'Which score given to the stated purpose of admission of the student is most common among applications?', 'What is the score for the recommendation letters presented by the student with the lowest English score?', 'What is the university rating of the applicant who is less likely to be admitted?', 'Which rating given to the stated purpose of students is associated with the highest accumulated grade point average?', 'Which rating number is most commonly given by universities?', 'Do most students have some research experience prior to the application?', 'What is the highest graduate record score in the dataset?', 'What is the average English score of applicants who have at least some research experience?', 'What is the total number of applicants with a university rating of 3?', 'What is the maximum grade point average among applicants without research experience?', 'What is the minimum score of letters presented among applicants who have over an eighty per cent chance of admission?', 'What is the standard deviation of CGPA scores?', 'What is the sum of English test scores for applicants with an stated purpose better than 4?', 'How many applicants have a graduate record score between 300 and 310 (including both)?', 'List the 5 highest graduate record scores in the dataset.', 'How many people in the dataset got a perfect English score?', 'How many applicants got a perfect score in their statement of purpose?', 'List the top 5 English scores in the dataset.', 'List the 5 lowest grade point average scores in the dataset.', 'List the top 5 stated purpose scores in the dataset.', 'List the top 5 scores assigned to endorsement letters in the dataset.', 'List the top 5 English scores of applicants who have experience as researchers.', 'List the best 2 graduate record scores of applicants whose stated motivation to enter got a rating better than 4.', 'List the 2 worst grade point average scores of applicants who received the second worst possible rating from their university.', 'List the university ratings associated with the top 5 CGPA scores.', 'List the university ratings of the lowest 5 grade point average scores.', 'List the scores given to the stated motivations of the 4 applicants who have the best shot at getting into the university they applied to.', 'List the SOP ratings of applicants with the top 5 English scores.', 'List the LOR ratings of applicants with the lowest 5 gpa scores.', 'Is there any individual in the dataset with a body mass index greater than 50?', 'Is it true that the number of regions represented are more than 3?', 'Is it true that there are no centenarians in this dataset? ', 'Is the average BMI found in this dataset considered not to be obese?', 'Are there any childless individuals?', 'Does the dataset contain people who do not consume tobacco?', 'Is there anyone that is a northeastern?', 'Would an individual with the median BMI of the dataset considered to be underweight?', 'Is the maximum medical charge in the dataset greater than $60,000?', 'What is the location most represented in this dataset?', 'Which gender has the highest number of individuals?', 'What is the smoking status of the individual who paid the most money?', 'What is the region the youngest teenager comes from?', 'What is the gender of the person with the highest body mass index?', 'Is being childless the most common state for people in the dataset? True', 'What is the most frequent number of children?', 'What region is represented least in the dataset?', 'What is the smoking status of the individual with the lowest BMI?', 'What is the maximum BMI in the dataset?', 'What is the average number of children?', 'How many unique regions are in the dataset?', 'What is the sum of all medically related charges in the dataset?', 'How old is the youngest teenager in the dataset?', 'How many people in the dataset have lived for more than six decades?', 'How many people could be considered smokers?', 'What is the median BMI in the dataset?', 'List the 2 highest BMIs in the dataset for people who can be considered to suffer from Class III Obesity.', 'List the charges of individuals with the 3 highest BMIs.', 'List the ages of individuals with the 5 lowest charges.', 'List the ages of the 3 youngest teenagers.', 'List the unique different smoking statuses found among individuals over 60 years of age.', 'List the regions of individuals with the 3 highest BMIs.', 'Is there a lifter older than 50?', 'Does the dataset contain squatting lifts?', 'Is the biggest lift performed greater than 880 pounds?', 'Is the minimum lifted less than 330 pounds?', 'Are there more than 100 lifters in the weight class someone that weights 82kg would compete in?', \"Is the average age of all lifting records in the '105 kg' weight class above 40?\", 'Is the average age of all lifting records in the weight class of someone who weights 103000 grams above 40?', \"Does 'Jessica Wilson' appear in the dataset?\", 'Are there fewer than 5 unique types of exercise recorded?', 'Which weight class has the best average lifted weight?', \"What is the most common 'Weight Class'?\", 'Which type of exercise has the best average lift?', \"What is the current record in kilograms for maximum weight ever lifted'?\", 'How many different athletes are there in the dataset?', 'How many different men can we find in this dataset?', 'How many different women are there in the dataset?', \"What's the highest record set by men in the bench press category?\", \"What's the best record set by women in the bench press category?\", 'Who is the woman with the best lifting record?', 'What is the total sum of the amounts lifted in a bench press exercise?', 'What is the least amount of kilos lifted in the weight class that someone who is 55kg would participate in?', 'What is the difference betweent the highest amount lifted and the lowest?', 'How many lifters are in the weight class that people who weight 139 pounds would enter?', 'What are the highest 3 amounts ever lifted by anyone?', 'List the 5 smallest amounts ever lifted by anyone.', \"What are the top 5 total lifts by 'Weight Class'?\", 'What are the 3 largest age gaps present between lifts for each weight class?', \"List the 2 worst lifts in the '105 kg' weight class.\", 'List the top 3 amounts lifted while squatting.', 'List the 5 names of the women lifting in this dataset', 'List the 5 men names of men who perform exercises in this dataset', \"What are the top 3 'Weight Classes' by total lifts?\", \"List 5 lifters from the '74 kg' weight class.\", 'What are the 3 least frequent types of exercise we find in the dataset?', 'What are the 3 most frequent types of exercise we find in the dataset?', 'Is there any condition where the mortality rate is more prevalent than a condition with a rate of 300?', 'Are there more cases recorded in cities overall?', 'Is the maximum mortality rate in the dataset worse than 250?', 'Does the dataset include any case with an error less than 0.5?', 'Are all values associated with the death rate higher than 100?', 'Are all of the most frequent causes of mortality related to the heart?', 'Does any region appear more than 50 times?', 'Are there more cases recorded for men than for women?', 'What is the region with the most deaths per capita?', 'What cause corresponds to the lowest mortality rate?', 'What gender has the worst average mortality rate?', 'What is the type of status with the best average ratio?', 'What region has the worst average rate?', 'What is the maximum value in the ratio column?', 'What is the minimum error present in this dataset?', 'How many cases have a death rate worse than 200?', 'What is the total sum of all death rate values?', 'What is the average error recorded?', 'What is the standard deviation of ratio?', 'How many distinct HHS regions are present?', 'What is the range (max-min) that death rates for any cause of death appearing in this dataset can take?', 'What are the 5 worst death rates recorded?', 'What are the lowest 5 values for error deviations recorded for the rates?', 'List the 5 smallest ratio values that are still greater than 100.', 'List the highest 4 deviations recorded to the expected rate recorded in urban areas.', 'List the 5 smallest deviations from the expected death rate in relation to diseases of the heart.', 'List the unique causes for death found in the first region of the United States Department of Health and Human Services.', 'What are the 3 regions with the worst average mortality rate?', 'What are the 2 categories present in the dataset that discriminate if a case happened in a city-like environment or not?', 'Is there a player with exactly a thousand total points in a given season? Answer True or False', 'Is there a season where any player scored more than 3000 points? Answer True or False', 'Did any player not miss any free throws in a single season? Answer True or False ', 'Is there a team that had a player scoring exactly 2k points in one season? Answer True or False', 'Is there any player with a number of rebounds better than 500 in a single season? Answer True or False', 'Did any player ever achieve more than 500 assists in one season? Answer True or False', 'Did any player play in every game of a season? Answer True or False', 'Is there any player with a field goal record for a given season/playoffs better than 9/10?', 'Which player scored the most points in the season that finished in 2013?', 'Which player scored the most points in the season that started in 2012?', 'Which team had the highest total points scored by its players?', 'What is the player name with the highest yet non-perfect free throw performance in the 2012-2013 year?', 'Which team had the most rebounds?', 'Who led in assists in the regular season that started in 2012?', 'Which player had the most steals in a given season?', 'What is the highest number of steals in a given season?', 'What is the total number of rebounds recorded in the dataset?', \"What is the total number of rebounds recorded in the dataset where the ball didn't change possession?\", 'In what percentage of the rebounds recorded in the dataset did the ball remain on the same team? Answer with a number', 'How many games did the player with the most minutes played in a single season play in that season?', 'What is the record set for single-season assists within the dataset?', 'How many players played in the 2010-11 season?', 'How many players scored exactly 2000 points in a season?', 'What was the highest number of blocks by any player in a season?', 'List the three highest rebound totals by a single player in one season.', 'What are the three highest total assist values in one season?', 'List the top 4 total point achieved by a single player in one season.', 'List the three highest numbers of steals.', 'List the top 3 block counts in the dataset.', 'List the 5 players with the least games played.', 'List the three players with the most rebounds.', 'List the top 5 of teams with the highest total points overall.', 'List the top 5 of teams with the highest total rebounds overall.', 'List the 2 players with the most steals overall.', 'List the three players with the highest blocks in a single season.', 'List the top 4 players by assists in a single given season.', 'Is there any woman in the dataset with a BMI greater than 30?', 'Is there any woman younger than 18 years?', 'Does the dataset contain any woman who has never been pregnant?', 'Are all women in the dataset younger than 40 years?', 'Does every woman in the dataset have an associated height strictly greater than 1.40 meters?', 'Is there at least one woman with heredity marked positively?', 'Are all women in the dataset predicted to be free of diabetes? (to have diabetes is associated with the positive label of the model)', 'How many teen pregnancies are there in this dataset?', 'Is there a woman with a weight of exactly 50000 grams?', 'What is the most value of the status marking hereditary diabetes risk in the dataset?', 'What is the age of the woman with the lowest body mass index?', 'What is the maximum height amongst the two heaviest women?', 'Which number of pregnancies is most common?', 'What is the most frequent BMI value in the dataset?', 'How much does the heaviest person in the dataset weight?', 'How tall is the shortest person in the dataset? Answer with the number of meters.', 'What is the average BMI across all women?', 'What is the total number of women in the dataset?', 'What is the median age of women in the dataset?', 'How many women weight less than 60 kg?', 'What is the range (max-min) of the different heights in meters? Answer with a single number', 'What is the standard deviation found among the BMIs?', 'List the 3 heights of the 3 tallest women in the dataset (in cm).', 'List the different ages (in years) of teenagers found in the dataset.', 'Provide a list with the unique reported pregnancy numbers of women weighing more (>) than 70000g. If there are none answer with an empty list.', 'List the weights of women with a height of exactly 1m and 45cm.', 'List the different labels assigned to heredity statuses.', 'List the different prediction outcomes for diabetes found in the dataset.', 'List the unique height values (converted to cm) found among of women with a BMI<18.5.', 'List the unique pregnancy numbers of women older than 30 years. If there are none answer with an empty list.', 'List the unique ages of the youngest five women who have a diabetes risk associated with their family. If there are less than five answer with all the unique ages that match the criteria.', 'Is there any record where the area affected is greater than 50ha?', 'Was there any fire unaffected by wind?', \"Is the maximum value of 'DMC' less than 200?\", 'Are all of the horizontal axis coordinates plotted to the right of the third column?', 'Are there any entries where the temperature is below freezing level in Celsius?', 'Is there any measuring that recorded 0% humidity ?', 'Are there more than 10 unique months in the dataset?', 'Are all months of the year present in the dataset?', 'Is the average value of wind speed recorded faster than 3?', 'If the year starts in January, what is the numeric id of the worst month in terms of number of fires?', 'Answer with the numeric ID of the day of the week the hottest temperature was recorded', 'What is the name of the month that recorded the driest day when a fire took place?', 'What is the label id of the month with the largest area burned?', 'What is the name of the windiest day on average?', \"What is the name of the month with the smallest average 'DC' value?\", \"Which month number corresponds to the highest average 'ISI' value?\", \"Which day was the minimum 'DMC' value recorded? Answer with the day's name\", 'What is the hottest temperature recorded?', 'What is the speed of the slowest wind in our records?', 'Assuming fires are always in different terrain, what is the total added area affected by fires in the dataset?', 'How many unique values are there in the vertical axis column?', 'What is the mean percentage of relative humidity? Answer with a number', \"What is the range (max - min) of 'DC' values?\", \"What is the standard deviation of the 'ISI' column?\", 'How many fires affected a negligible (zero) amount of terrain?', 'What are the 3 hottest temperatures recorded?', \"List the 5 smallest values in the 'DC' column.\", 'Provide the unique values in the vertical axis of the associated graph from bottom to top.', 'What are the 4 recorded humidity percentages of the 4 driest records?', 'List the 5 (can be repeated) highest wind speeds recorded.', 'Provide the size of the top 3 greatest areas a fire affected.', \"List the minimum 3 'DMC' values in ascending order.\", 'List the unique full month names when fires were recorded in ascending order.', 'Provide the 3 names of the days when fires were most frequently recorded. ', 'What are the 2 full names of the 2 months the first 2 rows of the database took place in?', 'Provide the name of the days when the 3 highest temperatures were recorded. ', 'List the unique month names corresponding to the driest 4 percentages of RH.', \"Provide the unique day names associated with the highest 5 'DMC' values.\", 'List the unique full names of the days where wind speed has been faster than 5mph.', ' Is there a transaction where more than 10 products were sold?', ' Is 99 an existing id for a store?', ' Do all rows of this dataset have a different product id?', 'Did we ever sell 20 items in the same transaction?', 'Is there any single product with a price greater than 100?', 'Does the dataset have fewer than 200k rows?', 'Do we have a separate category for drinking chocolate in our stores?', 'Is 5 the ID of the store with the most transactions?', 'What is the location of our most popular store?', 'Which category is associated with the smallest single product price in the database?', 'Which are the first three letters of day of the week which has worst performance in terms of revenue?', 'What is the product type of the transactions with yielded the most money in revenue? Answer with a category.', 'What are the first three letters of the month that has the highest average products per transaction?', 'Which hour has the lowest number of transactions? Answer with a number from 0 to 23.', 'What is the location of the first purchase row-wise?', 'What is the categorization of the first product row-wise?', 'What is the maximum amount of products that were sold in a single given transaction?', 'How many unique different products do we sell?', 'What is the total revenue provided by all the transactions in the dataset?', 'Are our stores open on Sunday?', 'What is the average unitary price in our transactions?', 'What is the total number of transactions carried on a Sunday?', 'How many active stores do we own according to this dataset?', 'How much revenue did our best single transaction bring?', 'How many transactions occurred in the sixth month of the year?', 'List the 3 largest amount of products bought in one transaction? If there are less than 3 list as many as there are.', 'List the different store ids', 'List the lowest 4 single-product price values', 'List highest 3 different revenues a given transaction has yielded?', 'List the unique numerical weekly values present in this dataset', 'What are the different locations where our business is present?', 'What are the unique product_category names in transactions with transaction_qty > 5? If there are none answer with an empty list', 'What are the 3 most common product_type names?', 'What are the abbreviated month names where transactions have been present?', 'Could you list the unique weekday names our transactions are recorded in?', ' List the IDs of our 2 most popular stores in terms of number of purchases', ' What are the 2 (non-unique) product types associated with the highest 2 revenues of a single given purchase? Answer with a list with 2 elements.', ' What is the name of the animal involved in the production of the most expensive coffee-related product that we offer? Answer with a value present in a cell of the database.', 'Do we have any book on sale? Answer True or False', 'Are there any books that are longer than 500 pages? Answer True or False', 'Did Mr Harari write a book on history? Answer True or False', 'Does any book have a rating better than 35? Answer True or False', 'Do we still have enough stock of all books? Answer True or False', \"A customer asked for a book titled 'The greatest book to ever exist', do we have it in stock? Answer True or False\", 'Is there any book published by Harper Collins for India?', 'Are there any books with fewer than 100 pages?', 'Which book is considered the best by our clients?', 'Assuming all books are similar in reading difficulty, which category does the book that would take longest to read belong to?', \"How many suns were there in the title of Hosseinis' novel? Answer with a number\", 'How many books are written by multiple authors? (explicitly mentioned translators and editors count as authors)', 'Who was the book with most reviewed book written by?', \"If I wanted to buy the shortest book, how long would be the book that I'd pick?\", 'What is the publisher of the nineteenth edition of Let Us C?', \"How much stock (in number of books) of Ben Graham's work is there in this store?\", 'Which category does the Quran belong to?', \"According to this database, how many editions has 'The Intelligent Investor' gone through?\", 'What is the total number of book pages in our database?', 'If I can read 200 pages a day and I want to pick a book that I can read in half a day, what is the number of books that I can choose from?', 'What is the average rating of all books?', 'If we had 30 copies of the arabic reader this morning, how many have we sold?', 'How many pages does Sapiens have?', 'How many books could be said to fall in the islamic category?', 'How many books have been reviewed more than 10 times?', 'What is the total number of books that we are selling below their usual price?', 'List the page counts of the first five books in the dataset?', 'List the page lengths (in numeric form) of the first five books?', 'List the ratings of the top four books with the most reviews?', 'Provide me with a list containing all the lengths of the books about computer science.', 'List the number of copies left for the first five books.', 'List the ratings of the last five books in the dataset', \"List the page counts of books in the 'History and Tradition' category?\", \"What is the stock of the book that is closest to running out copies but hasn't yet?.\", 'List the categories of the first five books.', 'List the authors of books that are not on sale today.', 'List the titles of books with fewer than 200 pages.', 'List the categories of books with ratings above 20.', 'List the authors of books with more than 10 reviews.', 'List the 5 categories of the last five books in the dataset.', \"List the editions of books in the 'Business, Investment and Economics' category.\"]\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1b6GVYWFmeya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables_comp={\n",
        "        \"066_IBM_HR\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/066_IBM_HR/all.parquet\"),\n",
        "        \"067_TripAdvisor\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/067_TripAdvisor/all.parquet\"),\n",
        "        \"068_WorldBank_Awards\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/068_WorldBank_Awards/all.parquet\"),\n",
        "        \"069_Taxonomy\":pd.read_parquet(\"/content/drive/MyDrive/competition/competition/069_Taxonomy/all.parquet\"),\n",
        "        \"070_OpenFoodFacts\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/070_OpenFoodFacts/all.parquet\"),\n",
        "        \"071_COL\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/071_COL/all.parquet\"),\n",
        "        \"072_Admissions\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/072_Admissions/all.parquet\"),\n",
        "        \"073_Med_Cost\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/073_Med_Cost/all.parquet\"),\n",
        "        \"074_Lift\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/074_Lift/all.parquet\"),\n",
        "        \"075_Mortality\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/075_Mortality/all.parquet\"),\n",
        "       \"076_NBA\":pd.read_parquet(\"/content/drive/MyDrive/competition/competition/076_NBA/all.parquet\"),\n",
        "        \"077_Gestational\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/077_Gestational/all.parquet\"),\n",
        "        \"078_Fires\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/078_Fires/all.parquet\"),\n",
        "        \"079_Coffee\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/079_Coffee/all.parquet\"),\n",
        "        \"080_Books\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/080_Books/all.parquet\"),\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "tables_databench={}\n",
        "for table_name, df in tables_comp.items():\n",
        "        print(f\"\\nTesting {table_name} table:\")\n",
        "        print(f\"Table shape: {df.shape}\")\n",
        "        print(\"Columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwRsJRTeY_AD",
        "outputId": "9376da3c-0a08-4a56-a1dc-c116809ec3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing 066_IBM_HR table:\n",
            "Table shape: (1470, 35)\n",
            "Columns: ['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
            "\n",
            "Testing 067_TripAdvisor table:\n",
            "Table shape: (20000, 10)\n",
            "Columns: ['ratings', 'title', 'text', 'author', 'date_stayed', 'offering_id', 'num_helpful_votes', 'date', 'id', 'via_mobile']\n",
            "\n",
            "Testing 068_WorldBank_Awards table:\n",
            "Table shape: (239461, 20)\n",
            "Columns: ['Procurement Method', 'Fiscal Year', 'Project Global Practice', 'WB Contract Number', 'Review type', 'Borrower Contract Reference Number', 'Supplier ID', 'Contract Description', 'Supplier Country Code', 'Borrower Country', 'Procurement Category', 'Region', 'Project ID', 'Supplier Country', 'Supplier', 'Borrower Country Code', 'Project Name', 'Contract Signing Date', 'As of Date', 'Supplier Contract Amount (USD)']\n",
            "\n",
            "Testing 069_Taxonomy table:\n",
            "Table shape: (703, 8)\n",
            "Columns: ['Unique ID', 'Parent', 'Name', 'Tier 1', 'Tier 2', 'Tier 3', 'Tier 4', 'Unnamed: 7']\n",
            "\n",
            "Testing 070_OpenFoodFacts table:\n",
            "Table shape: (9483, 11)\n",
            "Columns: ['categories_en', 'code', 'product_name', 'brands', 'labels_en', 'stores', 'countries_en', 'ingredients_analysis_tags', 'ingredients_tags', 'states_en', 'creator']\n",
            "\n",
            "Testing 071_COL table:\n",
            "Table shape: (121, 8)\n",
            "Columns: ['Rank', 'Country', 'Cost of Living Index', 'Rent Index', 'Cost of Living Plus Rent Index', 'Groceries Index', 'Restaurant Price Index', 'Local Purchasing Power Index']\n",
            "\n",
            "Testing 072_Admissions table:\n",
            "Table shape: (500, 9)\n",
            "Columns: ['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance of Admit']\n",
            "\n",
            "Testing 073_Med_Cost table:\n",
            "Table shape: (1338, 7)\n",
            "Columns: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
            "\n",
            "Testing 074_Lift table:\n",
            "Table shape: (3000, 5)\n",
            "Columns: ['Lifter Name', 'Age', 'Weight Class', 'Lift Type', 'Amount Lifted (kg)']\n",
            "\n",
            "Testing 075_Mortality table:\n",
            "Table shape: (400, 7)\n",
            "Columns: ['rownames', 'Region', 'Status', 'Sex', 'Cause', 'Rate', 'SE']\n",
            "\n",
            "Testing 076_NBA table:\n",
            "Table shape: (8835, 30)\n",
            "Columns: ['year', 'Season_type', 'PLAYER_ID', 'RANK', 'PLAYER', 'TEAM_ID', 'TEAM', 'GP', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'EFF', 'AST_TOV', 'STL_TOV']\n",
            "\n",
            "Testing 077_Gestational table:\n",
            "Table shape: (1012, 7)\n",
            "Columns: ['Age', 'Pregnancy No', 'Weight', 'Height', 'BMI', 'Heredity', 'Prediction']\n",
            "\n",
            "Testing 078_Fires table:\n",
            "Table shape: (517, 15)\n",
            "Columns: ['area', 'X', 'Y', 'month', 'day', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'calendar_names_1', 'calendar_names_2', 'calendar_1', 'calendar_2']\n",
            "\n",
            "Testing 079_Coffee table:\n",
            "Table shape: (149116, 15)\n",
            "Columns: ['transaction_id', 'transaction_qty', 'store_id', 'store_location', 'product_id', 'unit_price', 'product_category', 'product_type', 'product_detail', 'Revenue', 'Month', 'Month_1', 'Weekday', 'Weekday_1', 'Hour']\n",
            "\n",
            "Testing 080_Books table:\n",
            "Table shape: (40, 13)\n",
            "Columns: ['Book Title', 'Author', 'Category', 'Price (TK)', 'Stock Status', 'Copies Left', 'Book Length (Pages)', 'Edition', 'Publication', 'Wished Users', 'Discount Offer', 'Ratings', 'Reviews']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large datasets:\n",
        "Testing 068_WorldBank_Awards table:\n",
        "Table shape: (239461, 20)\n",
        "\n",
        "Testing 079_Coffee table:\n",
        "Table shape: (149116, 15)"
      ],
      "metadata": {
        "id": "o4GIWAe4mfUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "\n",
        "count_dic={}\n",
        "for i,j in grouped_counts.iterrows():\n",
        "  count_dic[j['dataset']]=j['no of questions']\n",
        "print(count_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE9JgUFInyKJ",
        "outputId": "a475988e-2f87-4341-d94f-2b63915a65a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'066_IBM_HR': 39, '067_TripAdvisor': 29, '068_WorldBank_Awards': 34, '069_Taxonomy': 35, '070_OpenFoodFacts': 29, '071_COL': 36, '072_Admissions': 39, '073_Med_Cost': 32, '074_Lift': 35, '075_Mortality': 29, '076_NBA': 36, '077_Gestational': 31, '078_Fires': 39, '079_Coffee': 38, '080_Books': 41}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from typing import List, Dict, Any\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "predicted_answers = []\n",
        "\n",
        "class UniversalTableQA:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing QA model...\")\n",
        "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "        self.model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.table_analysis = None\n",
        "        print(f\"Model initialized on {self.device}\")\n",
        "\n",
        "    def determine_chunk_size(self, df: pd.DataFrame) -> int:\n",
        "        \"\"\"\n",
        "        Determine optimal chunk size based on table characteristics.\n",
        "\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            int: Optimal chunk size\n",
        "        \"\"\"\n",
        "        total_rows = len(df)\n",
        "        num_columns = len(df.columns)\n",
        "\n",
        "        # Calculate average row size (approximate)\n",
        "        sample_size = min(1000, total_rows)\n",
        "        sample_memory = df.head(sample_size).memory_usage(deep=True).sum() / sample_size\n",
        "\n",
        "        # Base chunk size on table characteristics\n",
        "        if sample_memory > 1024 * 1024:  # If average row size > 1MB\n",
        "            base_chunk_size = 10\n",
        "        elif sample_memory > 1024 * 100:  # If average row size > 100KB\n",
        "            base_chunk_size = 20\n",
        "        else:\n",
        "            base_chunk_size = 30\n",
        "\n",
        "        # Adjust based on number of columns\n",
        "        if num_columns > 20:\n",
        "            base_chunk_size = max(5, base_chunk_size // 2)\n",
        "        elif num_columns < 5:\n",
        "            base_chunk_size = min(50, base_chunk_size * 2)\n",
        "\n",
        "        # Adjust based on total rows\n",
        "        if total_rows < 100:\n",
        "            return min(base_chunk_size, total_rows)\n",
        "        elif total_rows < 1000:\n",
        "            return min(base_chunk_size, total_rows // 4)\n",
        "        else:\n",
        "            return min(base_chunk_size, total_rows // 10)\n",
        "\n",
        "    def analyze_table_structure(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze table structure to understand its characteristics\"\"\"\n",
        "        analysis = {\n",
        "            'total_rows': len(df),\n",
        "            'total_columns': len(df.columns),\n",
        "            'column_types': {},\n",
        "            'unique_values': {},\n",
        "            'categorical_columns': [],\n",
        "            'numerical_columns': [],\n",
        "            'text_columns': []\n",
        "        }\n",
        "\n",
        "        for col in df.columns:\n",
        "            dtype = df[col].dtype\n",
        "            unique_count = df[col].nunique()\n",
        "\n",
        "            analysis['column_types'][col] = str(dtype)\n",
        "            analysis['unique_values'][col] = unique_count\n",
        "\n",
        "            if pd.api.types.is_numeric_dtype(dtype):\n",
        "                analysis['numerical_columns'].append(col)\n",
        "            elif unique_count < len(df) * 0.5:\n",
        "                analysis['categorical_columns'].append(col)\n",
        "            else:\n",
        "                analysis['text_columns'].append(col)\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def detect_question_type(self, question: str, table_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Detect the type of question and relevant columns\"\"\"\n",
        "        question = question.lower()\n",
        "        analysis = {\n",
        "            'type': 'UNKNOWN',\n",
        "            'relevant_columns': [],\n",
        "            'operations': [],\n",
        "            'conditions': {},\n",
        "            'question_text': question\n",
        "        }\n",
        "\n",
        "        # Detect yes/no questions\n",
        "        if question.startswith(('is ', 'are ', 'does ', 'do ', 'has ', 'have ', 'can ', 'will ', 'should ')):\n",
        "            analysis['type'] = 'BOOLEAN'\n",
        "            # Extract condition value\n",
        "            for col in table_analysis['categorical_columns'] + table_analysis['text_columns']:\n",
        "                col_lower = col.lower()\n",
        "                if col_lower in question:\n",
        "                    analysis['relevant_columns'].append(col)\n",
        "                    # Try to find the value being compared\n",
        "                    words = question.split()\n",
        "                    col_idx = next((i for i, word in enumerate(words) if col_lower in word), -1)\n",
        "                    if col_idx != -1 and col_idx + 1 < len(words):\n",
        "                        analysis['conditions'][col] = words[col_idx + 1]\n",
        "\n",
        "        # Existing question type detection\n",
        "        elif any(word in question for word in ['how many', 'count', 'total']):\n",
        "            analysis['type'] = 'AGGREGATE'\n",
        "            analysis['operations'].append('COUNT')\n",
        "        elif any(word in question for word in ['average', 'mean']):\n",
        "            analysis['type'] = 'AGGREGATE'\n",
        "            analysis['operations'].append('MEAN')\n",
        "        elif 'list' in question:\n",
        "            analysis['type'] = 'LIST'\n",
        "        elif any(word in question for word in ['maximum', 'highest', 'most common', 'most frequent']):\n",
        "            analysis['type'] = 'EXTREME'\n",
        "            analysis['operations'].append('MAX')\n",
        "        elif any(word in question for word in ['minimum', 'lowest', 'least']):\n",
        "            analysis['type'] = 'EXTREME'\n",
        "            analysis['operations'].append('MIN')\n",
        "\n",
        "        # Find relevant columns if not already found\n",
        "        if not analysis['relevant_columns']:\n",
        "            for col in table_analysis['categorical_columns'] + table_analysis['text_columns']:\n",
        "                if col.lower() in question:\n",
        "                    analysis['relevant_columns'].append(col)\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def process_boolean_query(self, df: pd.DataFrame, question_analysis: Dict) -> bool:\n",
        "        \"\"\"Process yes/no questions\"\"\"\n",
        "        try:\n",
        "            if question_analysis['relevant_columns'] and question_analysis['conditions']:\n",
        "                for col, condition_value in question_analysis['conditions'].items():\n",
        "                    # Check if the condition value exists in the column\n",
        "                    values = df[col].astype(str).str.lower()\n",
        "                    condition_value = condition_value.lower()\n",
        "                    return condition_value in values.values\n",
        "\n",
        "            # Handle existence questions\n",
        "            question = question_analysis['question_text']\n",
        "            if any(word in question for word in ['exist', 'exists', 'any']):\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    return not df[col].empty and not df[col].isna().all()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in boolean query processing: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def process_direct_query(self, df: pd.DataFrame, question_analysis: Dict) -> Any:\n",
        "        \"\"\"Process queries that can be answered directly from the DataFrame\"\"\"\n",
        "        try:\n",
        "            # Handle boolean questions first\n",
        "            if question_analysis['type'] == 'BOOLEAN':\n",
        "                return self.process_boolean_query(df, question_analysis)\n",
        "\n",
        "            # Existing query processing logic\n",
        "            if question_analysis['type'] == 'AGGREGATE':\n",
        "                if 'COUNT' in question_analysis['operations']:\n",
        "                    if question_analysis['relevant_columns']:\n",
        "                        col = question_analysis['relevant_columns'][0]\n",
        "                        return len(df[col].dropna().unique())\n",
        "                    return len(df)\n",
        "\n",
        "            elif question_analysis['type'] == 'LIST':\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    return sorted(df[col].dropna().unique().tolist())\n",
        "\n",
        "            elif question_analysis['type'] == 'EXTREME':\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    if 'MAX' in question_analysis['operations']:\n",
        "                        if col in self.table_analysis['categorical_columns']:\n",
        "                            value_counts = df[col].value_counts()\n",
        "                            if not value_counts.empty:\n",
        "                                return value_counts.index[0]\n",
        "                        else:\n",
        "                            return df[col].max()\n",
        "                    elif 'MIN' in question_analysis['operations']:\n",
        "                        if col in self.table_analysis['categorical_columns']:\n",
        "                            value_counts = df[col].value_counts()\n",
        "                            if not value_counts.empty:\n",
        "                                return value_counts.index[-1]\n",
        "                        else:\n",
        "                            return df[col].min()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in direct query processing: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def format_answer(self, answer: Any, question_analysis: Dict) -> str:\n",
        "        \"\"\"Format the answer based on question type\"\"\"\n",
        "        if answer is None:\n",
        "            return \"Unable to find an answer\"\n",
        "\n",
        "        if question_analysis['type'] == 'BOOLEAN':\n",
        "            return \"True\" if answer else \"False\"\n",
        "\n",
        "        if isinstance(answer, list):\n",
        "            return \", \".join(str(x) for x in answer if pd.notna(x)) if answer else \"No items found\"\n",
        "\n",
        "        return str(answer)\n",
        "\n",
        "    # Rest of the class implementation remains the same\n",
        "    def create_context_from_row(self, row: pd.Series) -> str:\n",
        "        \"\"\"Create a natural language context from a row\"\"\"\n",
        "        context_parts = []\n",
        "        for col, value in row.items():\n",
        "            if pd.notna(value):\n",
        "                context_parts.append(f\"{col}: {value}\")\n",
        "        return \", \".join(context_parts)\n",
        "    def predict(self, df: pd.DataFrame, question: str) -> str:\n",
        "        \"\"\"Main prediction function\"\"\"\n",
        "        self.table_analysis = self.analyze_table_structure(df)\n",
        "        question_analysis = self.detect_question_type(question, self.table_analysis)\n",
        "\n",
        "        direct_answer = self.process_direct_query(df, question_analysis)\n",
        "        if direct_answer is not None:\n",
        "            return self.format_answer(direct_answer, question_analysis)\n",
        "\n",
        "        # Determine chunk size dynamically\n",
        "        chunk_size = self.determine_chunk_size(df)\n",
        "        chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
        "\n",
        "        print(f\"Processing table with {len(chunks)} chunks (chunk size: {chunk_size})\")\n",
        "\n",
        "        best_answer = None\n",
        "        max_confidence = -float('inf')\n",
        "\n",
        "        for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n",
        "            context = \"\\n\".join(self.create_context_from_row(row) for _, row in chunk.iterrows())\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                question,\n",
        "                context,\n",
        "                max_length=512,\n",
        "                padding=True,\n",
        "                truncation='only_second',\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                start_scores = outputs.start_logits\n",
        "                end_scores = outputs.end_logits\n",
        "\n",
        "                start_idx = torch.argmax(start_scores)\n",
        "                end_idx = torch.argmax(end_scores) + 1\n",
        "                confidence = torch.max(start_scores).item() + torch.max(end_scores).item()\n",
        "\n",
        "                if confidence > max_confidence:\n",
        "                    answer_tokens = inputs['input_ids'][0][start_idx:end_idx]\n",
        "                    best_answer = self.tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
        "                    max_confidence = confidence\n",
        "\n",
        "        return self.format_answer(best_answer, question_analysis)\n"
      ],
      "metadata": {
        "id": "f8wRaoDbm7h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[ :2]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i==key:\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 1: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions1.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[ :batch_size].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions1.txt'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJyTf_nsr_3Z",
        "outputId": "240827bb-46d4-4486-94b1-7e980631f43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions1.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['066_IBM_HR', '067_TripAdvisor']\n",
            "----------------------------------------------------------\n",
            "Batch 1: size:68\n",
            "----------------------------------------------------------\n",
            "1. Question: Is our average employee older than 35?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:11<00:00,  8.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Question: Is the most frequent travel value rarely traveling?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Question: Is the highest DailyRate equal to 1499?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Question: Is the highest DailyRate negative?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5. Question: Is our research dept bigger than sales?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 10.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6. Question: Is the highest rating given to any performance to 4?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7. Question: Are there more employees who travel frequently than those who work in the HR department?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8. Question: Is the average MonthlyIncome of employees affected by attrition less than those not affected?\n",
            "9. Question: Is the standard number of working hours the same across all employees?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10. Question: What is the most common role?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11. Question: Which department has the highest average YearsAtCompany?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:10<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12. Question: What is the least common marital status?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13. Question: What is the most frequent field of education for our employees?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14. Question: Which travel category has the highest average income?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15. Question:  Which gender is most satisfied with the job on average?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16. Question: What is the most common score given work and life balance?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17. Question: Which EducationField do we employ the least?\n",
            "18. Question: What is the average age of our employees?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19. Question: What is the total number of different job roles offered by IBM?\n",
            "20. Question: What is the maximum years someone has been at IBM?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21. Question: What is the median monthly income of our employees?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22. Question: What is the sum of the miles employees have to travel to get to work?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23. Question: What is the average number of total working years for employees who are working in sales?\n",
            "24. Question: How many employees rate their satisfaction with their environment with a score of 4?\n",
            "25. Question: What is the range (max - min) of YearsSinceLastPromotion?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26. Question: What is the longest time someone has been without a promotion?\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27. Question: List the unique different grades received by anyone for their performance.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28. Question: List the amounts of the lowest 5 monthly incomes.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29. Question: List all the different education levels of our employees can be classified into.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30. Question: List the top 5 highest PercentSalaryHike values. The answer is a list with five values, even if they are repeated.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31. Question: List the 5 most common ages of our employees.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32. Question: List the top 3 most common job roles our company has.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33. Question: List the 2 departments that employ the most people.\n",
            "34. Question: List the different marital status values in our database.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35. Question: List all the different (unique) values we use to classify the field of education of our employees.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:08<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36. Question: List the top 5 BusinessTravel categories.\n",
            "37. Question: List all the unique possible values overtime can take.\n",
            "38. Question: List the 4 most common JobLevels.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:09<00:00, 10.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39. Question: List the 3 most common JobLevels.\n",
            "Processing table with 98 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 98/98 [00:07<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40. Question: Does the dataset contain any review that more than forty users have labeled as helpful?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:32<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41. Question: Are all the reviews sources (phone or not phone) non-null?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:33<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42. Question: Is 1 the least frequent overall rating given in a review?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43. Question: How many reviews give ratings related to the location?\n",
            "44. Question: Is there more overall ratings given than ratings related to the location?\n",
            "45. Question: Is there any review written in 2024?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:32<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46. Question: Are all of our reviews labelled helpful by someone?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:48<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47. Question: Are there more reviews marked as being made from a phone than not?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:41<00:00,  4.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48. Question: Is the maximum number of helpful votes found in only one review?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:32<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49. Question: Is the best possible review for room ratings found in more than fifteen reviews?\n",
            "50. Question: Which year had the highest number of reviews made?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:40<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51. Question: What is the average rating given to rooms?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [03:20<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52. Question: What (non-null) room rating is most common?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:38<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53. Question: Which value is most frequent for num_helpful_votes`?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:58<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54. Question: Who is the author of 'value with a view'?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:45<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55. Question: What is the average review length (in characters) without taking the title into account?\n",
            "56. Question: What is the total number of reviews?\n",
            "57. Question: What is the highest number of users that has labeled a single review as helpful?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58. Question: What is the average number of helpful votes?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:31<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59. Question: What is the length of the longest text of a review (in chars)?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60. Question: What is the year of the first review made?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:31<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61. Question: How many reviews did family fun guru write?\n",
            "62. Question: What is the sum of all helpful votes for these reviews?\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63. Question: List the top 4 years according to the number of reviews.\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64. Question: List the 5 (non-unique) highest values of `num_helpful_votes`.\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:31<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65. Question: List the usernames of the authors who provided a username and wrote more than 3 reviews. If there are none answer with an empty list.\n",
            "66. Question: List the usernames of the authors who provided a username and wrote more than 4 reviews. If there are none answer with an empty list.\n",
            "67. Question: List the 5 largest non-unique (they can be repeated) offering IDs.\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68. Question: List the 4 most common years a guest stayed at a property.\n",
            "Processing table with 667 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 667/667 [02:30<00:00,  4.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "skipped dataset: 3rd dataset\n",
        "size: 34\n",
        "Range:0-67\n",
        "\n",
        "\n",
        "next: 102 to 202(100)"
      ],
      "metadata": {
        "id": "sg9kEoNKyGfc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_X_SSk4RjDxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grouped_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TltUteGq2HaG",
        "outputId": "3e9667f7-6c6b-4801-b1e9-951bf8fc6751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 dataset  no of questions\n",
            "0             066_IBM_HR               39\n",
            "1        067_TripAdvisor               29\n",
            "2   068_WorldBank_Awards               34\n",
            "3           069_Taxonomy               35\n",
            "4      070_OpenFoodFacts               29\n",
            "5                071_COL               36\n",
            "6         072_Admissions               39\n",
            "7           073_Med_Cost               32\n",
            "8               074_Lift               35\n",
            "9          075_Mortality               29\n",
            "10               076_NBA               36\n",
            "11       077_Gestational               31\n",
            "12             078_Fires               39\n",
            "13            079_Coffee               38\n",
            "14             080_Books               41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[ 3:6]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i in list(count_dic.keys()):\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 2: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions2.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[102:202].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions2.txt'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d43ee9cb2d074223bb0a857a8a63b285",
            "9d8deda8951545e49b5a7d87158e6f4c",
            "b6142b0557b74b23ad4e76b3f7fa08f7",
            "cc4d6cab361a4fc1b0a3ca08b5dbbce9",
            "ab0dd553b2164b97a6e245e0f275ca2f",
            "70d40d2945fa443eb364cdfdb662c561",
            "7cd89f88fc784c84a40326f2dba4d047",
            "c5083c3a200944d48fa281bcae819e05",
            "0b198e778f294782868531b1320c9bad",
            "b1e8fe7afb2f45afb9f386e96fd74572",
            "56482cad62b44dea821d5bd0028d33c8",
            "392691c2745643a985137f433684b39c",
            "064657706c844c2f827c99d6ed12ce96",
            "50203869064e420c98382d0667013be1",
            "a75328fa4ba44ea799fc07d36aa5c32d",
            "223bdb39e1ea421685ac6753bef0875c",
            "a247316b1e714cbea0d54e6d3e72f4e9",
            "c432108993be4e408b56abb10e328699",
            "d3508c62113545e99e2e14d07709c928",
            "c3a49e26529e4f7bac6fccf08a97d7f1",
            "994db5a61f124919ad6c545ba4a0fbae",
            "faa071cda7eb45fbb3ee8acc4d31c356",
            "ecc8090ea8194dbba2c9950aaadf3ce7",
            "f510db135fdb4764836b54669f126bf8",
            "d8f20eef06c745a396ff487bd5a671e1",
            "bd2a58e209ce4ec8a014b3c3cf6ea743",
            "6c667a128d8645ecb8e69d2040dc8a98",
            "d5f874e42404426daadd4c290928ea9e",
            "b12a8743cf2143d08f632cc46c0add8a",
            "137cc6a530d14433bcae0b727a5ee9f7",
            "9804e11fabfd44ac812e0fa1e4ff39c8",
            "369bc5fec6e641e5807c9be2f03e29b6",
            "f50a9526633e4c1c87739373f4ac7980",
            "7b7410a73efe4986baba56df5f04e4df",
            "73c1982ca10a4f0ab8d8a50f2bc02450",
            "5a500085c54443a680d9a1764a5e8f7f",
            "5610979aafb143b4b464fd9c2856de6e",
            "c6493d5854b847c49311c0bc01a81cb2",
            "3cda847b6f4e4b8ab19bb64db189303d",
            "b792ecad6e5143b9aae374574720dc66",
            "dfe30a49a4024b89822736207479e1a6",
            "e2b2a5d4fd014f21b154bf78b673df01",
            "a19907b18c334ef085d7f8560f143bd3",
            "258c22209fff4178b763b5a69cbfe41d",
            "0c85d48b149c40bd85674aecf4ed8c0c",
            "780b863d6109441691dba858593e89c0",
            "c943b038d2ae4d7d9898a33c1b73cfab",
            "01fa202b1b3f48d282e229688d905400",
            "2a6c85c8cb4046a6975272af1504606b",
            "3738d75d6a3b45ff82639ac1ee468ef9",
            "5374361a506f49d5904f88a4c34041d8",
            "9cc560723ea24331b49bacfada922d14",
            "75613268e02e482989581da9f8167140",
            "138c8aef60e149afa6291a2c7db81e22",
            "4ef365173f464fcbb6316e64495a338b"
          ]
        },
        "id": "MmevZ387zAUy",
        "outputId": "32f6f63f-0af5-4221-f97d-701a264c145c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions2.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d43ee9cb2d074223bb0a857a8a63b285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "392691c2745643a985137f433684b39c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecc8090ea8194dbba2c9950aaadf3ce7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b7410a73efe4986baba56df5f04e4df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c85d48b149c40bd85674aecf4ed8c0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['069_Taxonomy', '070_OpenFoodFacts', '071_COL']\n",
            "----------------------------------------------------------\n",
            "Batch 2: size:102\n",
            "----------------------------------------------------------\n",
            "103. Question: Is there a first tier category with a name related to attractions?\n",
            "104. Question: Are there more than five first tier categories?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:01<00:00, 14.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105. Question: Is any entry in the third tier a (direct or otherwise) descendant of 150?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 33.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106. Question: Are all rows named?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107. Question: Are there any fourth level entities in the taxonomy?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 35.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108. Question: Are there more entities with a valid parent ID than third tier entities?\n",
            "109. Question: Does the dataset contain exactly 703 entries?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110. Question: Do all entities have a valid unique value associated?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 36.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111. Question: Which first tier category name has the most descendants? (direct or otherwise)\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 35.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112. Question: What is most common category name among the first level categories?\n",
            "Error in direct query processing: Categorical is not ordered for operation max\n",
            "you can use .as_ordered() to change the Categorical to an ordered one\n",
            "\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 27.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113. Question: Which first tier category has the second largest amount of descendants (direct or otherwise)?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:01<00:00, 17.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114. Question: What is the second most popular category name among the first level categories?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:01<00:00, 22.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115. Question: What is the most common unique parent ID found in the dataset?\n",
            "116. Question: What is the non-null third level value in the dataset that appears first?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:01<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117. Question: What is the name of the direct ascendant of the bars and restaurants entity?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 29.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118. Question: How many elements are there in our taxonomy?\n",
            "119. Question: How many elements in the taxonomy do not have a parent id associated?\n",
            "120. Question: What is the total number of unique non-null Parent values?\n",
            "121. Question: How many entries belong to the third or fourth tiers?\n",
            "122. Question: How many unique entries exist in the first level of our taxonomy?\n",
            "123. Question: How many rows contain null values in Tier 2?\n",
            "124. Question: How many Parent IDs appear exactly once?\n",
            "125. Question: Are all names unique?\n",
            "126. Question: What is the number of unique names?\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127. Question: List the 3 Parent values associated the 3 highest number of descendants (direct or otherwise).\n",
            "128. Question: List the entry counts for the attractions and automotive entities.\n",
            "129. Question: List the number of children for the categories of commercial trucks and convertibles. Answer with a two element list.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130. Question: List counts of non-null values for each Tier column.\n",
            "131. Question: List the first (by number of appearance) 3 different values in the highest tier of the dataset. If there are less than 3 list as many as there are.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132. Question: List the first (by row number) 2 different level 1 values found in the dataset. If there are less than 2 list as many as there are.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 34.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133. Question: List the first (by number of appearance) 4 different second highest level values.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 35.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134. Question: List all (unique) highest tier values present in the first 4 rows.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 35.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135. Question: List the 4 first tier values present in the first 4 rows.\n",
            "Processing table with 24 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 24/24 [00:00<00:00, 35.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136. Question: List the first 4 different non-null parent values found in the dataset. If there are less than 4 list as many as there are.\n",
            "137. Question: List the first 3 different non-null parent values found in the dataset. If there are less than 3 list as many as there are.\n",
            "138. Question: Is there any vegan product in our dataset?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139. Question: Did Eduardo create upload any products to the database?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140. Question: Is the product with code 00001522 apt for vegans?\n",
            "141. Question: Is any product palm oil free?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142. Question: Are there any products belonging to the category 'Plant-based foods and beverages'?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143. Question: Are all products created by the openfoodfacts contributors labeled as vegan?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144. Question:  Are more than a 1000 products sold in Mercadona stores?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145. Question: Are there products from the 'Hacendado' brand in more than one country?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146. Question: What is the most frequent brand name? Answer with a single category.\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147. Question: Which country has the most products listed? Answer with a single category.\n",
            "148. Question: What is the single label associated with the most products? Answer with a single category.\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149. Question: How many products are labeled as 'Vegan'?\n",
            "150. Question: Which store has the most products listed?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151. Question: Which creator has contributed the most to the database?\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152. Question: How many products belong to the 'Hacendado' brand?\n",
            "153. Question: How many unique countries exist in the dataset?\n",
            "154. Question: How many products have no labels?\n",
            "155. Question: How many products are associated with the 'Mercadona' type of store?\n",
            "156. Question: What is the total number of products in the dataset that have a non-empty product name?\n",
            "157. Question: What is the total number of products in the dataset that have a unique product code?\n",
            "158. Question: How many products are listed under 'Plant-based foods and beverages'?\n",
            "159. Question:  List the product codes associated with the Seitan category\n",
            "160. Question:  List the product names associated with the Seitan category\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161. Question: List the two most frequent labels in the dataset\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162. Question:  \"List the five most frequent labels in the dataset. If there are less than five list as many as there are.\"\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:47<00:00,  6.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163. Question:  List the two most frequent store names in the dataset\n",
            "Processing table with 317 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 317/317 [00:46<00:00,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164. Question:  List the two number of stores for the two most frequent store names in the dataset\n",
            "165. Question:  List the 3 most frequent countries in the dataset\n",
            "166. Question:  List the 3 number of products present for the 3 most frequent countries in the dataset\n",
            "167. Question: Is Switzerland the country with the highest Cost of Living Index?\n",
            "168. Question: Is the Bahamas ranked second in the dataset?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169. Question: Is there any country with a Rent Index above 65?\n",
            "170. Question: Does Iceland have more purchasing power than a country that has a 100 in that index?\n",
            "171. Question: Is Barbados considered overall more expensive than the country ranked in the 10th place?\n",
            "172. Question: Does the dataset include at least 120 countries?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 24.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173. Question: If I am from Iceland and I move to Singapore, would I expect my rent to be more expensive according to the index?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174. Question: Is Switzerland considered to be the most expensive country regardless if I rent or own my home?\n",
            "175. Question: Which country ranks the most expensive in terms of overall cost of living?\n",
            "176. Question: In which country would it be cheaper to buy groceries?\n",
            "177. Question: If I have to rent but I want to move to the cheapest country to live in, where should I move to?\n",
            "178. Question: In which country would it be most expensive to eat in a restaurant?\n",
            "179. Question: Which country has the second-highest world rent?\n",
            "180. Question: Which country is the second most expensive destination to move to considering I am not a home owner in the country?\n",
            "181. Question: Which country has a Groceries Index closest to 80?\n",
            "182. Question: What is the Cost of Living Index assigned to the most expensive country to live in?\n",
            "183. Question: What is the Rent Index of the top-ranked country?\n",
            "184. Question: What is the total number of countries in the dataset?\n",
            "185. Question: What is the average Groceries Index across all countries?\n",
            "186. Question: What is the difference between the highest and lowest Restaurant Price Index?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187. Question: If I'm moving to Singapore and I have to rent there, what would my associated index for cost of living be?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188. Question: What is the mean Local Purchasing Power Index of the top 10 countries by rank?\n",
            "189. Question: What is Iceland's rank?\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 25.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190. Question: List the Rent Index values of the top 5 overall most expensive countries excluding rent.\n",
            "191. Question: List the Cost of Living Index values of the 5 countries that are ranked the cheapest.\n",
            "192. Question: List the Local Purchasing Power Index values of countries ranked 1st to 5th.\n",
            "193. Question: List the 3 associated index values for the countries where groceries are most expensive.\n",
            "194. Question: List the index given to restaurant prices for the top 5 overall most expensive countries for home owners.\n",
            "195. Question: List the 5 lowest indices for cost of life for a person who have to rent.\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 26.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196. Question: List the 5 Local Purchasing Power Index values closest to 100.\n",
            "Processing table with 5 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 5/5 [00:00<00:00, 24.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197. Question: List the names of the top 5 ranked countries.\n",
            "198. Question: List the 3 countries where I would pay the most for groceries.\n",
            "199. Question: List the 3 countries where it's cheapest to rent.\n",
            "200. Question: List the countries ranked 10th to 15th.\n",
            "201. Question: List the top 5 countries by Local Purchasing Power Index.\n",
            "202. Question: List the 3 countries where restaurants are the cheapest.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blYcELSjdEG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch : 3\n",
        "start:202\n",
        "end:308"
      ],
      "metadata": {
        "id": "yWtBnWoqdFBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[ 6:9]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i in list(count_dic.keys()):\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 3: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions3.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[202:308].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions3.txt'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUWA-Pg3dEOO",
        "outputId": "6cd3ec83-7a42-4bf6-869d-e5fb04fa7690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions3.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['072_Admissions', '073_Med_Cost', '074_Lift']\n",
            "----------------------------------------------------------\n",
            "Batch 3: size:102\n",
            "----------------------------------------------------------\n",
            "203. Question: Is there any applicant who got a grade better than 330 in their graduate record examination?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204. Question: Is there any applicant who got a score worse than 100 in their English test?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205. Question: Is the best CGPA greater than 9.5?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206. Question: Did any applicant with a perfect university rating score get a grade below 320 in their graduate record examination?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207. Question: Is there an applicant with a chance above 95 per cent of getting into the university they applied to?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208. Question: Is the lowest score assigned to a student's stated purpose for admission worse than 2?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209. Question: Are there any applicants who don't have any research experience previous to their application?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210. Question: Is the average English score better than 105?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211. Question: What is the rating given by the college they applied to to the applicant with the highest CGPA?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212. Question: What is the university rating of the applicant with the lowest GRE score?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 16.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213. Question: Which score given to the stated purpose of admission of the student is most common among applications?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 10.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "214. Question: What is the score for the recommendation letters presented by the student with the lowest English score?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 16.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215. Question: What is the university rating of the applicant who is less likely to be admitted?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 17.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216. Question: Which rating given to the stated purpose of students is associated with the highest accumulated grade point average?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217. Question: Which rating number is most commonly given by universities?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218. Question: Do most students have some research experience prior to the application?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219. Question: What is the highest graduate record score in the dataset?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220. Question: What is the average English score of applicants who have at least some research experience?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221. Question: What is the total number of applicants with a university rating of 3?\n",
            "222. Question: What is the maximum grade point average among applicants without research experience?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223. Question: What is the minimum score of letters presented among applicants who have over an eighty per cent chance of admission?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224. Question: What is the standard deviation of CGPA scores?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225. Question: What is the sum of English test scores for applicants with an stated purpose better than 4?\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226. Question: How many applicants have a graduate record score between 300 and 310 (including both)?\n",
            "227. Question: List the 5 highest graduate record scores in the dataset.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228. Question: How many people in the dataset got a perfect English score?\n",
            "229. Question: How many applicants got a perfect score in their statement of purpose?\n",
            "230. Question: List the top 5 English scores in the dataset.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231. Question: List the 5 lowest grade point average scores in the dataset.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 23.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232. Question: List the top 5 stated purpose scores in the dataset.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 16.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233. Question: List the top 5 scores assigned to endorsement letters in the dataset.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 16.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234. Question: List the top 5 English scores of applicants who have experience as researchers.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:01<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235. Question: List the best 2 graduate record scores of applicants whose stated motivation to enter got a rating better than 4.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 17.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236. Question: List the 2 worst grade point average scores of applicants who received the second worst possible rating from their university.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237. Question: List the university ratings associated with the top 5 CGPA scores.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 24.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238. Question: List the university ratings of the lowest 5 grade point average scores.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239. Question: List the scores given to the stated motivations of the 4 applicants who have the best shot at getting into the university they applied to.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240. Question: List the SOP ratings of applicants with the top 5 English scores.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 26.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241. Question: List the LOR ratings of applicants with the lowest 5 gpa scores.\n",
            "Processing table with 17 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 17/17 [00:00<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "242. Question: Is there any individual in the dataset with a body mass index greater than 50?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 35.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "243. Question: Is it true that the number of regions represented are more than 3?\n",
            "244. Question: Is it true that there are no centenarians in this dataset? \n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245. Question: Is the average BMI found in this dataset considered not to be obese?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "246. Question: Are there any childless individuals?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247. Question: Does the dataset contain people who do not consume tobacco?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 30.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "248. Question: Is there anyone that is a northeastern?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 24.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "249. Question: Would an individual with the median BMI of the dataset considered to be underweight?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250. Question: Is the maximum medical charge in the dataset greater than $60,000?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 35.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251. Question: What is the location most represented in this dataset?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252. Question: Which gender has the highest number of individuals?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "253. Question: What is the smoking status of the individual who paid the most money?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254. Question: What is the region the youngest teenager comes from?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255. Question: What is the gender of the person with the highest body mass index?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256. Question: Is being childless the most common state for people in the dataset? True\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257. Question: What is the most frequent number of children?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "258. Question: What region is represented least in the dataset?\n",
            "259. Question: What is the smoking status of the individual with the lowest BMI?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 26.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260. Question: What is the maximum BMI in the dataset?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261. Question: What is the average number of children?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 30.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262. Question: How many unique regions are in the dataset?\n",
            "263. Question: What is the sum of all medically related charges in the dataset?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264. Question: How old is the youngest teenager in the dataset?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265. Question: How many people in the dataset have lived for more than six decades?\n",
            "266. Question: How many people could be considered smokers?\n",
            "267. Question: What is the median BMI in the dataset?\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268. Question: List the 2 highest BMIs in the dataset for people who can be considered to suffer from Class III Obesity.\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269. Question: List the charges of individuals with the 3 highest BMIs.\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270. Question: List the ages of individuals with the 5 lowest charges.\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 35.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271. Question: List the ages of the 3 youngest teenagers.\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 36.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272. Question: List the unique different smoking statuses found among individuals over 60 years of age.\n",
            "Processing table with 45 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 45/45 [00:01<00:00, 27.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273. Question: List the regions of individuals with the 3 highest BMIs.\n",
            "274. Question: Is there a lifter older than 50?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 27.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275. Question: Does the dataset contain squatting lifts?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276. Question: Is the biggest lift performed greater than 880 pounds?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277. Question: Is the minimum lifted less than 330 pounds?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278. Question: Are there more than 100 lifters in the weight class someone that weights 82kg would compete in?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 27.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "279. Question: Is the average age of all lifting records in the '105 kg' weight class above 40?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 29.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280. Question: Is the average age of all lifting records in the weight class of someone who weights 103000 grams above 40?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281. Question: Does 'Jessica Wilson' appear in the dataset?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282. Question: Are there fewer than 5 unique types of exercise recorded?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "283. Question: Which weight class has the best average lifted weight?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:04<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "284. Question: What is the most common 'Weight Class'?\n",
            "285. Question: Which type of exercise has the best average lift?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "286. Question: What is the current record in kilograms for maximum weight ever lifted'?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 32.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "287. Question: How many different athletes are there in the dataset?\n",
            "288. Question: How many different men can we find in this dataset?\n",
            "289. Question: How many different women are there in the dataset?\n",
            "290. Question: What's the highest record set by men in the bench press category?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291. Question: What's the best record set by women in the bench press category?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 29.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "292. Question: Who is the woman with the best lifting record?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 29.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "293. Question: What is the total sum of the amounts lifted in a bench press exercise?\n",
            "294. Question: What is the least amount of kilos lifted in the weight class that someone who is 55kg would participate in?\n",
            "295. Question: What is the difference betweent the highest amount lifted and the lowest?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "296. Question: How many lifters are in the weight class that people who weight 139 pounds would enter?\n",
            "297. Question: What are the highest 3 amounts ever lifted by anyone?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298. Question: List the 5 smallest amounts ever lifted by anyone.\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299. Question: What are the top 5 total lifts by 'Weight Class'?\n",
            "300. Question: What are the 3 largest age gaps present between lifts for each weight class?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:04<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301. Question: List the 2 worst lifts in the '105 kg' weight class.\n",
            "302. Question: List the top 3 amounts lifted while squatting.\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 34.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303. Question: List the 5 names of the women lifting in this dataset\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304. Question: List the 5 men names of men who perform exercises in this dataset\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:02<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305. Question: What are the top 3 'Weight Classes' by total lifts?\n",
            "306. Question: List 5 lifters from the '74 kg' weight class.\n",
            "307. Question: What are the 3 least frequent types of exercise we find in the dataset?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 32.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308. Question: What are the 3 most frequent types of exercise we find in the dataset?\n",
            "Processing table with 100 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 100/100 [00:03<00:00, 26.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch 4\n",
        "start:308\n",
        "end:404"
      ],
      "metadata": {
        "id": "ndXT5bPdej6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[9:12]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i==key:\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 4: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions4.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[308:404].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions1.txt'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWmiM9q1fFsf",
        "outputId": "cc932aac-6dbd-4cf5-9a8a-e7de0c9e96f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions1.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['075_Mortality', '076_NBA', '077_Gestational']\n",
            "----------------------------------------------------------\n",
            "Batch 4: size:0\n",
            "----------------------------------------------------------\n",
            "309. Question: Is there any condition where the mortality rate is more prevalent than a condition with a rate of 300?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 19.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310. Question: Are there more cases recorded in cities overall?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 19.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311. Question: Is the maximum mortality rate in the dataset worse than 250?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 19.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312. Question: Does the dataset include any case with an error less than 0.5?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313. Question: Are all values associated with the death rate higher than 100?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 31.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314. Question: Are all of the most frequent causes of mortality related to the heart?\n",
            "315. Question: Does any region appear more than 50 times?\n",
            "316. Question: Are there more cases recorded for men than for women?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 32.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317. Question: What is the region with the most deaths per capita?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "318. Question: What cause corresponds to the lowest mortality rate?\n",
            "319. Question: What gender has the worst average mortality rate?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 34.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320. Question: What is the type of status with the best average ratio?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 34.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321. Question: What region has the worst average rate?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322. Question: What is the maximum value in the ratio column?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 33.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323. Question: What is the minimum error present in this dataset?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324. Question: How many cases have a death rate worse than 200?\n",
            "325. Question: What is the total sum of all death rate values?\n",
            "326. Question: What is the average error recorded?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327. Question: What is the standard deviation of ratio?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328. Question: How many distinct HHS regions are present?\n",
            "329. Question: What is the range (max-min) that death rates for any cause of death appearing in this dataset can take?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 36.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330. Question: What are the 5 worst death rates recorded?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 33.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331. Question: What are the lowest 5 values for error deviations recorded for the rates?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "332. Question: List the 5 smallest ratio values that are still greater than 100.\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 34.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333. Question: List the highest 4 deviations recorded to the expected rate recorded in urban areas.\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334. Question: List the 5 smallest deviations from the expected death rate in relation to diseases of the heart.\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 35.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335. Question: List the unique causes for death found in the first region of the United States Department of Health and Human Services.\n",
            "336. Question: What are the 3 regions with the worst average mortality rate?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 34.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "337. Question: What are the 2 categories present in the dataset that discriminate if a case happened in a city-like environment or not?\n",
            "Processing table with 14 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 14/14 [00:00<00:00, 36.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338. Question: Is there a player with exactly a thousand total points in a given season? Answer True or False\n",
            "339. Question: Is there a season where any player scored more than 3000 points? Answer True or False\n",
            "340. Question: Did any player not miss any free throws in a single season? Answer True or False \n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:30<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "341. Question: Is there a team that had a player scoring exactly 2k points in one season? Answer True or False\n",
            "342. Question: Is there any player with a number of rebounds better than 500 in a single season? Answer True or False\n",
            "343. Question: Did any player ever achieve more than 500 assists in one season? Answer True or False\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:32<00:00, 18.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344. Question: Did any player play in every game of a season? Answer True or False\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345. Question: Is there any player with a field goal record for a given season/playoffs better than 9/10?\n",
            "346. Question: Which player scored the most points in the season that finished in 2013?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:30<00:00, 19.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347. Question: Which player scored the most points in the season that started in 2012?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:30<00:00, 19.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348. Question: Which team had the highest total points scored by its players?\n",
            "349. Question: What is the player name with the highest yet non-perfect free throw performance in the 2012-2013 year?\n",
            "350. Question: Which team had the most rebounds?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "351. Question: Who led in assists in the regular season that started in 2012?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352. Question: Which player had the most steals in a given season?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353. Question: What is the highest number of steals in a given season?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:30<00:00, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354. Question: What is the total number of rebounds recorded in the dataset?\n",
            "355. Question: What is the total number of rebounds recorded in the dataset where the ball didn't change possession?\n",
            "356. Question: In what percentage of the rebounds recorded in the dataset did the ball remain on the same team? Answer with a number\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "357. Question: How many games did the player with the most minutes played in a single season play in that season?\n",
            "358. Question: What is the record set for single-season assists within the dataset?\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:31<00:00, 18.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359. Question: How many players played in the 2010-11 season?\n",
            "360. Question: How many players scored exactly 2000 points in a season?\n",
            "361. Question: What was the highest number of blocks by any player in a season?\n",
            "362. Question: List the three highest rebound totals by a single player in one season.\n",
            "363. Question: What are the three highest total assist values in one season?\n",
            "364. Question: List the top 4 total point achieved by a single player in one season.\n",
            "365. Question: List the three highest numbers of steals.\n",
            "Processing table with 589 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 589/589 [00:30<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366. Question: List the top 3 block counts in the dataset.\n",
            "367. Question: List the 5 players with the least games played.\n",
            "368. Question: List the three players with the most rebounds.\n",
            "369. Question: List the top 5 of teams with the highest total points overall.\n",
            "370. Question: List the top 5 of teams with the highest total rebounds overall.\n",
            "371. Question: List the 2 players with the most steals overall.\n",
            "372. Question: List the three players with the highest blocks in a single season.\n",
            "373. Question: List the top 4 players by assists in a single given season.\n",
            "374. Question: Is there any woman in the dataset with a BMI greater than 30?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 32.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375. Question: Is there any woman younger than 18 years?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "376. Question: Does the dataset contain any woman who has never been pregnant?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "377. Question: Are all women in the dataset younger than 40 years?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378. Question: Does every woman in the dataset have an associated height strictly greater than 1.40 meters?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "379. Question: Is there at least one woman with heredity marked positively?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380. Question: Are all women in the dataset predicted to be free of diabetes? (to have diabetes is associated with the positive label of the model)\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 24.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381. Question: How many teen pregnancies are there in this dataset?\n",
            "382. Question: Is there a woman with a weight of exactly 50000 grams?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 23.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383. Question: What is the most value of the status marking hereditary diabetes risk in the dataset?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 22.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384. Question: What is the age of the woman with the lowest body mass index?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 33.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385. Question: What is the maximum height amongst the two heaviest women?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386. Question: Which number of pregnancies is most common?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "387. Question: What is the most frequent BMI value in the dataset?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388. Question: How much does the heaviest person in the dataset weight?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389. Question: How tall is the shortest person in the dataset? Answer with the number of meters.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390. Question: What is the average BMI across all women?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391. Question: What is the total number of women in the dataset?\n",
            "392. Question: What is the median age of women in the dataset?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 36.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "393. Question: How many women weight less than 60 kg?\n",
            "394. Question: What is the range (max-min) of the different heights in meters? Answer with a single number\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "395. Question: What is the standard deviation found among the BMIs?\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396. Question: List the 3 heights of the 3 tallest women in the dataset (in cm).\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 25.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "397. Question: List the different ages (in years) of teenagers found in the dataset.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "398. Question: Provide a list with the unique reported pregnancy numbers of women weighing more (>) than 70000g. If there are none answer with an empty list.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:01<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "399. Question: List the weights of women with a height of exactly 1m and 45cm.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400. Question: List the different labels assigned to heredity statuses.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401. Question: List the different prediction outcomes for diabetes found in the dataset.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402. Question: List the unique height values (converted to cm) found among of women with a BMI<18.5.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403. Question: List the unique pregnancy numbers of women older than 30 years. If there are none answer with an empty list.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 35.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404. Question: List the unique ages of the youngest five women who have a diabetes risk associated with their family. If there are less than five answer with all the unique ages that match the criteria.\n",
            "Processing table with 34 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 34/34 [00:00<00:00, 34.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch 5:\n",
        "\n",
        "start:404\n",
        "end:443"
      ],
      "metadata": {
        "id": "OdTiAHTHiMUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[12:15]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i==key:\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 5: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions5.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[404:443].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions5.txt'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XJVSgWpiLw1",
        "outputId": "7bcbfe28-9f76-4cfe-c758-028549ec78d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions5.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['078_Fires', '079_Coffee', '080_Books']\n",
            "----------------------------------------------------------\n",
            "Batch 5: size:0\n",
            "----------------------------------------------------------\n",
            "405. Question: Is there any record where the area affected is greater than 50ha?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "406. Question: Was there any fire unaffected by wind?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 12.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "407. Question: Is the maximum value of 'DMC' less than 200?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 17.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "408. Question: Are all of the horizontal axis coordinates plotted to the right of the third column?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "409. Question: Are there any entries where the temperature is below freezing level in Celsius?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410. Question: Is there any measuring that recorded 0% humidity ?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "411. Question: Are there more than 10 unique months in the dataset?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "412. Question: Are all months of the year present in the dataset?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "413. Question: Is the average value of wind speed recorded faster than 3?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "414. Question: If the year starts in January, what is the numeric id of the worst month in terms of number of fires?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "415. Question: Answer with the numeric ID of the day of the week the hottest temperature was recorded\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416. Question: What is the name of the month that recorded the driest day when a fire took place?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "417. Question: What is the label id of the month with the largest area burned?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "418. Question: What is the name of the windiest day on average?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "419. Question: What is the name of the month with the smallest average 'DC' value?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 13.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420. Question: Which month number corresponds to the highest average 'ISI' value?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "421. Question: Which day was the minimum 'DMC' value recorded? Answer with the day's name\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422. Question: What is the hottest temperature recorded?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 19.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "423. Question: What is the speed of the slowest wind in our records?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "424. Question: Assuming fires are always in different terrain, what is the total added area affected by fires in the dataset?\n",
            "425. Question: How many unique values are there in the vertical axis column?\n",
            "426. Question: What is the mean percentage of relative humidity? Answer with a number\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "427. Question: What is the range (max - min) of 'DC' values?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428. Question: What is the standard deviation of the 'ISI' column?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429. Question: How many fires affected a negligible (zero) amount of terrain?\n",
            "430. Question: What are the 3 hottest temperatures recorded?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "431. Question: List the 5 smallest values in the 'DC' column.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "432. Question: Provide the unique values in the vertical axis of the associated graph from bottom to top.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 21.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "433. Question: What are the 4 recorded humidity percentages of the 4 driest records?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "434. Question: List the 5 (can be repeated) highest wind speeds recorded.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435. Question: Provide the size of the top 3 greatest areas a fire affected.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 17.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436. Question: List the minimum 3 'DMC' values in ascending order.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "437. Question: List the unique full month names when fires were recorded in ascending order.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 12.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438. Question: Provide the 3 names of the days when fires were most frequently recorded. \n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 13.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "439. Question: What are the 2 full names of the 2 months the first 2 rows of the database took place in?\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 19.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440. Question: Provide the name of the days when the 3 highest temperatures were recorded. \n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "441. Question: List the unique month names corresponding to the driest 4 percentages of RH.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:00<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "442. Question: Provide the unique day names associated with the highest 5 'DMC' values.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 13.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "443. Question: List the unique full names of the days where wind speed has been faster than 5mph.\n",
            "Processing table with 18 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 18/18 [00:01<00:00, 14.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grouped_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9cDGg6cjaKe",
        "outputId": "fdbdd1b0-ff98-438b-f8cf-f35ea8ed7957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 dataset  no of questions\n",
            "0             066_IBM_HR               39\n",
            "1        067_TripAdvisor               29\n",
            "2   068_WorldBank_Awards               34\n",
            "3           069_Taxonomy               35\n",
            "4      070_OpenFoodFacts               29\n",
            "5                071_COL               36\n",
            "6         072_Admissions               39\n",
            "7           073_Med_Cost               32\n",
            "8               074_Lift               35\n",
            "9          075_Mortality               29\n",
            "10               076_NBA               36\n",
            "11       077_Gestational               31\n",
            "12             078_Fires               39\n",
            "13            079_Coffee               38\n",
            "14             080_Books               41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch6:481\n",
        "\n",
        "start:\n",
        "end:522"
      ],
      "metadata": {
        "id": "bOe6HhRbi1Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    datasets=grouped_counts['dataset']\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "    batch_datasets = unique_datasets[12:15]\n",
        "    batch_size=0\n",
        "    for i ,key in zip(batch_datasets,count_dic):\n",
        "      if i==key:\n",
        "        batch_size+=count_dic[key]\n",
        "\n",
        "    print(batch_datasets)\n",
        "\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    print(f\"Batch 6: size:{batch_size}\")\n",
        "    print(f\"----------------------------------------------------------\")\n",
        "    with open(\"predictions6.txt\", \"a\") as file:\n",
        "      for index, row in question_answers[481:522].iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions6.txt'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVwv0Ln-i6bq",
        "outputId": "c32ed35a-8602-4b52-c51c-4a6d0728c762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions6.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "['078_Fires', '079_Coffee', '080_Books']\n",
            "----------------------------------------------------------\n",
            "Batch 6: size:0\n",
            "----------------------------------------------------------\n",
            "482. Question: Do we have any book on sale? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 18.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "483. Question: Are there any books that are longer than 500 pages? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "484. Question: Did Mr Harari write a book on history? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 17.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485. Question: Does any book have a rating better than 35? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 19.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "486. Question: Do we still have enough stock of all books? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 19.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487. Question: A customer asked for a book titled 'The greatest book to ever exist', do we have it in stock? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "488. Question: Is there any book published by Harper Collins for India?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489. Question: Are there any books with fewer than 100 pages?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490. Question: Which book is considered the best by our clients?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491. Question: Assuming all books are similar in reading difficulty, which category does the book that would take longest to read belong to?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "492. Question: How many suns were there in the title of Hosseinis' novel? Answer with a number\n",
            "493. Question: How many books are written by multiple authors? (explicitly mentioned translators and editors count as authors)\n",
            "494. Question: Who was the book with most reviewed book written by?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "495. Question: If I wanted to buy the shortest book, how long would be the book that I'd pick?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 17.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "496. Question: What is the publisher of the nineteenth edition of Let Us C?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 18.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497. Question: How much stock (in number of books) of Ben Graham's work is there in this store?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 18.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498. Question: Which category does the Quran belong to?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "499. Question: According to this database, how many editions has 'The Intelligent Investor' gone through?\n",
            "500. Question: What is the total number of book pages in our database?\n",
            "501. Question: If I can read 200 pages a day and I want to pick a book that I can read in half a day, what is the number of books that I can choose from?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502. Question: What is the average rating of all books?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "503. Question: If we had 30 copies of the arabic reader this morning, how many have we sold?\n",
            "504. Question: How many pages does Sapiens have?\n",
            "505. Question: How many books could be said to fall in the islamic category?\n",
            "506. Question: How many books have been reviewed more than 10 times?\n",
            "507. Question: What is the total number of books that we are selling below their usual price?\n",
            "508. Question: List the page counts of the first five books in the dataset?\n",
            "509. Question: List the page lengths (in numeric form) of the first five books?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510. Question: List the ratings of the top four books with the most reviews?\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511. Question: Provide me with a list containing all the lengths of the books about computer science.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512. Question: List the number of copies left for the first five books.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 18.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513. Question: List the ratings of the last five books in the dataset\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 19.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "514. Question: List the page counts of books in the 'History and Tradition' category?\n",
            "515. Question: What is the stock of the book that is closest to running out copies but hasn't yet?.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 17.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "516. Question: List the categories of the first five books.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "517. Question: List the authors of books that are not on sale today.\n",
            "518. Question: List the titles of books with fewer than 200 pages.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "519. Question: List the categories of books with ratings above 20.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "520. Question: List the authors of books with more than 10 reviews.\n",
            "521. Question: List the 5 categories of the last five books in the dataset.\n",
            "Processing table with 2 chunks (chunk size: 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "522. Question: List the editions of books in the 'Business, Investment and Economics' category.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables_comp_lite={\n",
        "        \"066_IBM_HR\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/066_IBM_HR/sample.parquet\"),\n",
        "        \"067_TripAdvisor\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/067_TripAdvisor/sample.parquet\"),\n",
        "        \"068_WorldBank_Awards\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/068_WorldBank_Awards/sample.parquet\"),\n",
        "        \"069_Taxonomy\":pd.read_parquet(\"/content/drive/MyDrive/competition/competition/069_Taxonomy/sample.parquet\"),\n",
        "        \"070_OpenFoodFacts\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/070_OpenFoodFacts/sample.parquet\"),\n",
        "        \"071_COL\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/071_COL/sample.parquet\"),\n",
        "        \"072_Admissions\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/072_Admissions/sample.parquet\"),\n",
        "        \"073_Med_Cost\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/073_Med_Cost/sample.parquet\"),\n",
        "        \"074_Lift\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/074_Lift/sample.parquet\"),\n",
        "        \"075_Mortality\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/075_Mortality/sample.parquet\"),\n",
        "       \"076_NBA\":pd.read_parquet(\"/content/drive/MyDrive/competition/competition/076_NBA/sample.parquet\"),\n",
        "        \"077_Gestational\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/077_Gestational/sample.parquet\"),\n",
        "        \"078_Fires\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/078_Fires/sample.parquet\"),\n",
        "        \"079_Coffee\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/079_Coffee/sample.parquet\"),\n",
        "        \"080_Books\": pd.read_parquet(\"/content/drive/MyDrive/competition/competition/080_Books/sample.parquet\"),\n",
        "\n",
        "    }\n",
        "\n",
        "for table_name, df in tables_comp_lite.items():\n",
        "        print(f\"\\nTesting {table_name} table:\")\n",
        "        print(f\"Table shape: {df.shape}\")\n",
        "        print(\"Columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpErTi2SbdSx",
        "outputId": "81514f93-0ab0-4a9c-bc1f-dbfccca82e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing 066_IBM_HR table:\n",
            "Table shape: (20, 35)\n",
            "Columns: ['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
            "\n",
            "Testing 067_TripAdvisor table:\n",
            "Table shape: (20, 10)\n",
            "Columns: ['ratings', 'title', 'text', 'author', 'date_stayed', 'offering_id', 'num_helpful_votes', 'date', 'id', 'via_mobile']\n",
            "\n",
            "Testing 068_WorldBank_Awards table:\n",
            "Table shape: (20, 20)\n",
            "Columns: ['Procurement Method', 'Fiscal Year', 'Project Global Practice', 'WB Contract Number', 'Review type', 'Borrower Contract Reference Number', 'Supplier ID', 'Contract Description', 'Supplier Country Code', 'Borrower Country', 'Procurement Category', 'Region', 'Project ID', 'Supplier Country', 'Supplier', 'Borrower Country Code', 'Project Name', 'Contract Signing Date', 'As of Date', 'Supplier Contract Amount (USD)']\n",
            "\n",
            "Testing 069_Taxonomy table:\n",
            "Table shape: (20, 8)\n",
            "Columns: ['Unique ID', 'Parent', 'Name', 'Tier 1', 'Tier 2', 'Tier 3', 'Tier 4', 'Unnamed: 7']\n",
            "\n",
            "Testing 070_OpenFoodFacts table:\n",
            "Table shape: (20, 11)\n",
            "Columns: ['categories_en', 'code', 'product_name', 'brands', 'labels_en', 'stores', 'countries_en', 'ingredients_analysis_tags', 'ingredients_tags', 'states_en', 'creator']\n",
            "\n",
            "Testing 071_COL table:\n",
            "Table shape: (20, 8)\n",
            "Columns: ['Rank', 'Country', 'Cost of Living Index', 'Rent Index', 'Cost of Living Plus Rent Index', 'Groceries Index', 'Restaurant Price Index', 'Local Purchasing Power Index']\n",
            "\n",
            "Testing 072_Admissions table:\n",
            "Table shape: (20, 9)\n",
            "Columns: ['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance of Admit']\n",
            "\n",
            "Testing 073_Med_Cost table:\n",
            "Table shape: (20, 7)\n",
            "Columns: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
            "\n",
            "Testing 074_Lift table:\n",
            "Table shape: (20, 5)\n",
            "Columns: ['Lifter Name', 'Age', 'Weight Class', 'Lift Type', 'Amount Lifted (kg)']\n",
            "\n",
            "Testing 075_Mortality table:\n",
            "Table shape: (20, 7)\n",
            "Columns: ['rownames', 'Region', 'Status', 'Sex', 'Cause', 'Rate', 'SE']\n",
            "\n",
            "Testing 076_NBA table:\n",
            "Table shape: (20, 30)\n",
            "Columns: ['year', 'Season_type', 'PLAYER_ID', 'RANK', 'PLAYER', 'TEAM_ID', 'TEAM', 'GP', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'EFF', 'AST_TOV', 'STL_TOV']\n",
            "\n",
            "Testing 077_Gestational table:\n",
            "Table shape: (20, 7)\n",
            "Columns: ['Age', 'Pregnancy No', 'Weight', 'Height', 'BMI', 'Heredity', 'Prediction']\n",
            "\n",
            "Testing 078_Fires table:\n",
            "Table shape: (20, 15)\n",
            "Columns: ['area', 'X', 'Y', 'month', 'day', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'calendar_names_1', 'calendar_names_2', 'calendar_1', 'calendar_2']\n",
            "\n",
            "Testing 079_Coffee table:\n",
            "Table shape: (20, 15)\n",
            "Columns: ['transaction_id', 'transaction_qty', 'store_id', 'store_location', 'product_id', 'unit_price', 'product_category', 'product_type', 'product_detail', 'Revenue', 'Month', 'Month_1', 'Weekday', 'Weekday_1', 'Hour']\n",
            "\n",
            "Testing 080_Books table:\n",
            "Table shape: (20, 13)\n",
            "Columns: ['Book Title', 'Author', 'Category', 'Price (TK)', 'Stock Status', 'Copies Left', 'Book Length (Pages)', 'Edition', 'Publication', 'Wished Users', 'Discount Offer', 'Ratings', 'Reviews']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMvSr6BfUS3p"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# # Load all QA pairs\n",
        "# all_qa = load_dataset(\"cardiffnlp/databench\", name=\"qa\", split=\"train\")\n",
        "\n",
        "# queries=[ all_qa['question'][i]for i in range(285,305)]\n",
        "# answers=[ all_qa['answer'][i] for i in range(285,305)]\n",
        "# columns_used=[ all_qa['columns_used'][i] for i in range(285,305)]\n",
        "# print(len(columns_used))\n",
        "# print(columns_used)\n",
        "# print(answers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"filename.txt\", \"a\") as file:\n",
        "    file.write(\"Content to append\\n\")\n"
      ],
      "metadata": {
        "id": "iK94DvBj4Nmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from typing import List, Dict, Any\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "predicted_answers = []\n",
        "\n",
        "class UniversalTableQA:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing QA model...\")\n",
        "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "        self.model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.table_analysis = None\n",
        "        print(f\"Model initialized on {self.device}\")\n",
        "\n",
        "    def determine_chunk_size(self, df: pd.DataFrame) -> int:\n",
        "        \"\"\"\n",
        "        Determine optimal chunk size based on table characteristics.\n",
        "\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            int: Optimal chunk size\n",
        "        \"\"\"\n",
        "        total_rows = len(df)\n",
        "        num_columns = len(df.columns)\n",
        "\n",
        "        # Calculate average row size (approximate)\n",
        "        sample_size = min(1000, total_rows)\n",
        "        sample_memory = df.head(sample_size).memory_usage(deep=True).sum() / sample_size\n",
        "\n",
        "        # Base chunk size on table characteristics\n",
        "        if sample_memory > 1024 * 1024:  # If average row size > 1MB\n",
        "            base_chunk_size = 10\n",
        "        elif sample_memory > 1024 * 100:  # If average row size > 100KB\n",
        "            base_chunk_size = 20\n",
        "        else:\n",
        "            base_chunk_size = 30\n",
        "\n",
        "        # Adjust based on number of columns\n",
        "        if num_columns > 20:\n",
        "            base_chunk_size = max(5, base_chunk_size // 2)\n",
        "        elif num_columns < 5:\n",
        "            base_chunk_size = min(50, base_chunk_size * 2)\n",
        "\n",
        "        # Adjust based on total rows\n",
        "        if total_rows < 100:\n",
        "            return min(base_chunk_size, total_rows)\n",
        "        elif total_rows < 1000:\n",
        "            return min(base_chunk_size, total_rows // 4)\n",
        "        else:\n",
        "            return min(base_chunk_size, total_rows // 10)\n",
        "\n",
        "    def analyze_table_structure(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze table structure to understand its characteristics\"\"\"\n",
        "        analysis = {\n",
        "            'total_rows': len(df),\n",
        "            'total_columns': len(df.columns),\n",
        "            'column_types': {},\n",
        "            'unique_values': {},\n",
        "            'categorical_columns': [],\n",
        "            'numerical_columns': [],\n",
        "            'text_columns': []\n",
        "        }\n",
        "\n",
        "        for col in df.columns:\n",
        "            dtype = df[col].dtype\n",
        "            unique_count = df[col].nunique()\n",
        "\n",
        "            analysis['column_types'][col] = str(dtype)\n",
        "            analysis['unique_values'][col] = unique_count\n",
        "\n",
        "            if pd.api.types.is_numeric_dtype(dtype):\n",
        "                analysis['numerical_columns'].append(col)\n",
        "            elif unique_count < len(df) * 0.5:\n",
        "                analysis['categorical_columns'].append(col)\n",
        "            else:\n",
        "                analysis['text_columns'].append(col)\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def detect_question_type(self, question: str, table_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Detect the type of question and relevant columns\"\"\"\n",
        "        question = question.lower()\n",
        "        analysis = {\n",
        "            'type': 'UNKNOWN',\n",
        "            'relevant_columns': [],\n",
        "            'operations': [],\n",
        "            'conditions': {},\n",
        "            'question_text': question\n",
        "        }\n",
        "\n",
        "        # Detect yes/no questions\n",
        "        if question.startswith(('is ', 'are ', 'does ', 'do ', 'has ', 'have ', 'can ', 'will ', 'should ')):\n",
        "            analysis['type'] = 'BOOLEAN'\n",
        "            # Extract condition value\n",
        "            for col in table_analysis['categorical_columns'] + table_analysis['text_columns']:\n",
        "                col_lower = col.lower()\n",
        "                if col_lower in question:\n",
        "                    analysis['relevant_columns'].append(col)\n",
        "                    # Try to find the value being compared\n",
        "                    words = question.split()\n",
        "                    col_idx = next((i for i, word in enumerate(words) if col_lower in word), -1)\n",
        "                    if col_idx != -1 and col_idx + 1 < len(words):\n",
        "                        analysis['conditions'][col] = words[col_idx + 1]\n",
        "\n",
        "        # Existing question type detection\n",
        "        elif any(word in question for word in ['how many', 'count', 'total']):\n",
        "            analysis['type'] = 'AGGREGATE'\n",
        "            analysis['operations'].append('COUNT')\n",
        "        elif any(word in question for word in ['average', 'mean']):\n",
        "            analysis['type'] = 'AGGREGATE'\n",
        "            analysis['operations'].append('MEAN')\n",
        "        elif 'list' in question:\n",
        "            analysis['type'] = 'LIST'\n",
        "        elif any(word in question for word in ['maximum', 'highest', 'most common', 'most frequent']):\n",
        "            analysis['type'] = 'EXTREME'\n",
        "            analysis['operations'].append('MAX')\n",
        "        elif any(word in question for word in ['minimum', 'lowest', 'least']):\n",
        "            analysis['type'] = 'EXTREME'\n",
        "            analysis['operations'].append('MIN')\n",
        "\n",
        "        # Find relevant columns if not already found\n",
        "        if not analysis['relevant_columns']:\n",
        "            for col in table_analysis['categorical_columns'] + table_analysis['text_columns']:\n",
        "                if col.lower() in question:\n",
        "                    analysis['relevant_columns'].append(col)\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def process_boolean_query(self, df: pd.DataFrame, question_analysis: Dict) -> bool:\n",
        "        \"\"\"Process yes/no questions\"\"\"\n",
        "        try:\n",
        "            if question_analysis['relevant_columns'] and question_analysis['conditions']:\n",
        "                for col, condition_value in question_analysis['conditions'].items():\n",
        "                    # Check if the condition value exists in the column\n",
        "                    values = df[col].astype(str).str.lower()\n",
        "                    condition_value = condition_value.lower()\n",
        "                    return condition_value in values.values\n",
        "\n",
        "            # Handle existence questions\n",
        "            question = question_analysis['question_text']\n",
        "            if any(word in question for word in ['exist', 'exists', 'any']):\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    return not df[col].empty and not df[col].isna().all()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in boolean query processing: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def process_direct_query(self, df: pd.DataFrame, question_analysis: Dict) -> Any:\n",
        "        \"\"\"Process queries that can be answered directly from the DataFrame\"\"\"\n",
        "        try:\n",
        "            # Handle boolean questions first\n",
        "            if question_analysis['type'] == 'BOOLEAN':\n",
        "                return self.process_boolean_query(df, question_analysis)\n",
        "\n",
        "            # Existing query processing logic\n",
        "            if question_analysis['type'] == 'AGGREGATE':\n",
        "                if 'COUNT' in question_analysis['operations']:\n",
        "                    if question_analysis['relevant_columns']:\n",
        "                        col = question_analysis['relevant_columns'][0]\n",
        "                        return len(df[col].dropna().unique())\n",
        "                    return len(df)\n",
        "\n",
        "            elif question_analysis['type'] == 'LIST':\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    return sorted(df[col].dropna().unique().tolist())\n",
        "\n",
        "            elif question_analysis['type'] == 'EXTREME':\n",
        "                if question_analysis['relevant_columns']:\n",
        "                    col = question_analysis['relevant_columns'][0]\n",
        "                    if 'MAX' in question_analysis['operations']:\n",
        "                        if col in self.table_analysis['categorical_columns']:\n",
        "                            value_counts = df[col].value_counts()\n",
        "                            if not value_counts.empty:\n",
        "                                return value_counts.index[0]\n",
        "                        else:\n",
        "                            return df[col].max()\n",
        "                    elif 'MIN' in question_analysis['operations']:\n",
        "                        if col in self.table_analysis['categorical_columns']:\n",
        "                            value_counts = df[col].value_counts()\n",
        "                            if not value_counts.empty:\n",
        "                                return value_counts.index[-1]\n",
        "                        else:\n",
        "                            return df[col].min()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in direct query processing: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def format_answer(self, answer: Any, question_analysis: Dict) -> str:\n",
        "        \"\"\"Format the answer based on question type\"\"\"\n",
        "        if answer is None:\n",
        "            return \"Unable to find an answer\"\n",
        "\n",
        "        if question_analysis['type'] == 'BOOLEAN':\n",
        "            return \"True\" if answer else \"False\"\n",
        "\n",
        "        if isinstance(answer, list):\n",
        "            return \", \".join(str(x) for x in answer if pd.notna(x)) if answer else \"No items found\"\n",
        "\n",
        "        return str(answer)\n",
        "\n",
        "    # Rest of the class implementation remains the same\n",
        "    def create_context_from_row(self, row: pd.Series) -> str:\n",
        "        \"\"\"Create a natural language context from a row\"\"\"\n",
        "        context_parts = []\n",
        "        for col, value in row.items():\n",
        "            if pd.notna(value):\n",
        "                context_parts.append(f\"{col}: {value}\")\n",
        "        return \", \".join(context_parts)\n",
        "    def predict(self, df: pd.DataFrame, question: str) -> str:\n",
        "        \"\"\"Main prediction function\"\"\"\n",
        "        self.table_analysis = self.analyze_table_structure(df)\n",
        "        question_analysis = self.detect_question_type(question, self.table_analysis)\n",
        "\n",
        "        direct_answer = self.process_direct_query(df, question_analysis)\n",
        "        if direct_answer is not None:\n",
        "            return self.format_answer(direct_answer, question_analysis)\n",
        "\n",
        "        # Determine chunk size dynamically\n",
        "        chunk_size = self.determine_chunk_size(df)\n",
        "        chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
        "\n",
        "        print(f\"Processing table with {len(chunks)} chunks (chunk size: {chunk_size})\")\n",
        "\n",
        "        best_answer = None\n",
        "        max_confidence = -float('inf')\n",
        "\n",
        "        for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n",
        "            context = \"\\n\".join(self.create_context_from_row(row) for _, row in chunk.iterrows())\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                question,\n",
        "                context,\n",
        "                max_length=512,\n",
        "                padding=True,\n",
        "                truncation='only_second',\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                start_scores = outputs.start_logits\n",
        "                end_scores = outputs.end_logits\n",
        "\n",
        "                start_idx = torch.argmax(start_scores)\n",
        "                end_idx = torch.argmax(end_scores) + 1\n",
        "                confidence = torch.max(start_scores).item() + torch.max(end_scores).item()\n",
        "\n",
        "                if confidence > max_confidence:\n",
        "                    answer_tokens = inputs['input_ids'][0][start_idx:end_idx]\n",
        "                    best_answer = self.tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
        "                    max_confidence = confidence\n",
        "\n",
        "        return self.format_answer(best_answer, question_analysis)\n",
        "\n",
        "def test_system():\n",
        "    qa_system = UniversalTableQA()\n",
        "\n",
        "    tables=tables_comp_lite\n",
        "    i=0\n",
        "    def remove_duplicates_preserve_order(input_list):\n",
        "      seen = set()\n",
        "      result = []\n",
        "      for item in input_list:\n",
        "          if item not in seen:\n",
        "              result.append(item)\n",
        "              seen.add(item)\n",
        "      return result\n",
        "    unique_datasets = remove_duplicates_preserve_order(datasets)\n",
        "    print(unique_datasets)\n",
        "    print(tables.keys())\n",
        "    count=0\n",
        "\n",
        "    with open(\"predictions_lite.txt\", \"a\") as file:\n",
        "      for index, row in question_answers.iterrows():\n",
        "        # Access question and dataset directly\n",
        "        question = row['question']\n",
        "        dataset = row['dataset']\n",
        "\n",
        "        print(f\"{index + 1}. Question: {question}\")\n",
        "\n",
        "        try:\n",
        "            # Predict the answer using the dataset and question\n",
        "            answer = qa_system.predict(tables[dataset], question)\n",
        "\n",
        "            # Refine the answer\n",
        "            refined_answer = answer.strip()\n",
        "\n",
        "            # Write the refined answer to the file\n",
        "            file.write(f\"{refined_answer}\\n\")\n",
        "        except Exception as e:\n",
        "            # Handle errors and log them\n",
        "            print(f\"Error for question {index + 1}: {e}\")\n",
        "            file.write(f\"{index + 1}. Error: Unable to generate an answer\\n\")\n",
        "\n",
        "print(\"Predictions saved to 'predictions_lite.txt'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du98IRczUgGS",
        "outputId": "f1c9f943-cc02-4116-8860-ceb206ba88da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions_lite.txt'.\n",
            "Initializing QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n",
            "['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books']\n",
            "dict_keys(['066_IBM_HR', '067_TripAdvisor', '068_WorldBank_Awards', '069_Taxonomy', '070_OpenFoodFacts', '071_COL', '072_Admissions', '073_Med_Cost', '074_Lift', '075_Mortality', '076_NBA', '077_Gestational', '078_Fires', '079_Coffee', '080_Books'])\n",
            "1. Question: Is our average employee older than 35?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Question: Is the most frequent travel value rarely traveling?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Question: Is the highest DailyRate equal to 1499?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Question: Is the highest DailyRate negative?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5. Question: Is our research dept bigger than sales?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6. Question: Is the highest rating given to any performance to 4?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7. Question: Are there more employees who travel frequently than those who work in the HR department?\n",
            "Processing table with 2 chunks (chunk size: 15)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8. Question: Is the average MonthlyIncome of employees affected by attrition less than those not affected?\n",
            "9. Question: Is the standard number of working hours the same across all employees?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10. Question: What is the most common role?"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11. Question: Which department has the highest average YearsAtCompany?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12. Question: What is the least common marital status?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13. Question: What is the most frequent field of education for our employees?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14. Question: Which travel category has the highest average income?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15. Question:  Which gender is most satisfied with the job on average?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16. Question: What is the most common score given work and life balance?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17. Question: Which EducationField do we employ the least?\n",
            "18. Question: What is the average age of our employees?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19. Question: What is the total number of different job roles offered by IBM?\n",
            "20. Question: What is the maximum years someone has been at IBM?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21. Question: What is the median monthly income of our employees?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22. Question: What is the sum of the miles employees have to travel to get to work?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23. Question: What is the average number of total working years for employees who are working in sales?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24. Question: How many employees rate their satisfaction with their environment with a score of 4?\n",
            "25. Question: What is the range (max - min) of YearsSinceLastPromotion?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26. Question: What is the longest time someone has been without a promotion?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27. Question: List the unique different grades received by anyone for their performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28. Question: List the amounts of the lowest 5 monthly incomes."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29. Question: List all the different education levels of our employees can be classified into.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30. Question: List the top 5 highest PercentSalaryHike values. The answer is a list with five values, even if they are repeated.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 16.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31. Question: List the 5 most common ages of our employees.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 16.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32. Question: List the top 3 most common job roles our company has.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33. Question: List the 2 departments that employ the most people.\n",
            "34. Question: List the different marital status values in our database.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 16.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35. Question: List all the different (unique) values we use to classify the field of education of our employees.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 16.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36. Question: List the top 5 BusinessTravel categories.\n",
            "37. Question: List all the unique possible values overtime can take.\n",
            "38. Question: List the 4 most common JobLevels.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 16.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39. Question: List the 3 most common JobLevels.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40. Question: Does the dataset contain any review that more than forty users have labeled as helpful?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41. Question: Are all the reviews sources (phone or not phone) non-null?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42. Question: Is 1 the least frequent overall rating given in a review?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43. Question: How many reviews give ratings related to the location?\n",
            "44. Question: Is there more overall ratings given than ratings related to the location?\n",
            "45. Question: Is there any review written in 2024?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46. Question: Are all of our reviews labelled helpful by someone?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47. Question: Are there more reviews marked as being made from a phone than not?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48. Question: Is the maximum number of helpful votes found in only one review?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49. Question: Is the best possible review for room ratings found in more than fifteen reviews?\n",
            "50. Question: Which year had the highest number of reviews made?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51. Question: What is the average rating given to rooms?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52. Question: What (non-null) room rating is most common?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53. Question: Which value is most frequent for num_helpful_votes`?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54. Question: Who is the author of 'value with a view'?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55. Question: What is the average review length (in characters) without taking the title into account?\n",
            "56. Question: What is the total number of reviews?\n",
            "57. Question: What is the highest number of users that has labeled a single review as helpful?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58. Question: What is the average number of helpful votes?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59. Question: What is the length of the longest text of a review (in chars)?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60. Question: What is the year of the first review made?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61. Question: How many reviews did family fun guru write?\n",
            "62. Question: What is the sum of all helpful votes for these reviews?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63. Question: List the top 4 years according to the number of reviews.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64. Question: List the 5 (non-unique) highest values of `num_helpful_votes`.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65. Question: List the usernames of the authors who provided a username and wrote more than 3 reviews. If there are none answer with an empty list.\n",
            "66. Question: List the usernames of the authors who provided a username and wrote more than 4 reviews. If there are none answer with an empty list.\n",
            "67. Question: List the 5 largest non-unique (they can be repeated) offering IDs.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68. Question: List the 4 most common years a guest stayed at a property.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69. Question: Does any entry in the dataset have a supplier contract greater than one million dollars?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70. Question: Is there any region which was awarded only one contract?\n",
            "71. Question: Is India amongst the borrower countries?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72. Question: Is India the borrower country with the most contracts awarded?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73. Question: Is there any project where the review is made before its execution?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74. Question: Is there any project where the review is made after its execution?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 13.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75. Question: Is any supplier from the US?\n",
            "76. Question: What is the most frequent method of procurement for a given contract?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77. Question: Which region has the most contracts?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78. Question: What is the longest name amongst the countries which have borrowed money? \n",
            "79. Question: What is the procurement category associated with the largest contract?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80. Question: Which region has the largest contracts on average?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81. Question: Who is the most frequent country of borrowers present in the dataset?\n",
            "82. Question: Which global project practice would appear first if we sorted the columnn from A to Z?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83. Question: How big is the biggest contract in the dataset? Answer in USD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 13.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84. Question: How many different fiscal years the contracts belong to?\n",
            "85. Question: What is the total number of procurements in the dataset?\n",
            "86. Question: How big is the average procurement across all entries?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87. Question: Assuming supplier IDs are assigned from lowest to highest, what is the ID of the oldest supplier present in the dataset?\n",
            "Error in direct query processing: Categorical is not ordered for operation max\n",
            "you can use .as_ordered() to change the Categorical to an ordered one\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88. Question: What is the standard deviation of the contracts awarded?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89. Question: What is the total number of supplier contracts in the 2024 fiscal year?\n",
            "90. Question: List the 3 quantities of usd associated with the top 3 biggest contracts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 13.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91. Question: Are there contracts awarded after the 2020 fiscal year had ended?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92. Question: Assuming new suppliers get the last assigned id + 1, what are the unique IDs of the earliest 5 different suppliers we have in the dataset?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93. Question: What are the 3 fiscal years that had the most procurements?\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 14.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94. Question: For each of the first three fiscal years present in this dataset list the total amount of dollars awarded.\n",
            "95. Question: List the amounts awarded to the 2 contracts that are strictly over 100k dollars but closest to 100,000USD.\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96. Question:  How much were the 4 largest contracts in central and west africa awarded for? Answer with a list with one amount per contract\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 13.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97. Question: List the 5 countries which most frequently borrow money through a procurement.\n",
            "98. Question: List the 4 regions the countries most frequently belong to.\n",
            "99. Question: List the 4 most frequent methods of procurement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100. Question: What are the first 4 (row-wise) distinct 'Supplier Countries' we can find in the dataset?\n",
            "101. Question: List the unique review methods for contracts awarded above five hundred thousand dollars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 15.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102. Question: List the unique review methods for contracts awarded more than 500000USD\n",
            "Processing table with 2 chunks (chunk size: 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 11.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103. Question: Is there a first tier category with a name related to attractions?\n",
            "104. Question: Are there more than five first tier categories?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105. Question: Is any entry in the third tier a (direct or otherwise) descendant of 150?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106. Question: Are all rows named?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107. Question: Are there any fourth level entities in the taxonomy?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108. Question: Are there more entities with a valid parent ID than third tier entities?\n",
            "109. Question: Does the dataset contain exactly 703 entries?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110. Question: Do all entities have a valid unique value associated?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111. Question: Which first tier category name has the most descendants? (direct or otherwise)\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112. Question: What is most common category name among the first level categories?\n",
            "Error in direct query processing: Categorical is not ordered for operation max\n",
            "you can use .as_ordered() to change the Categorical to an ordered one\n",
            "\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113. Question: Which first tier category has the second largest amount of descendants (direct or otherwise)?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114. Question: What is the second most popular category name among the first level categories?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115. Question: What is the most common unique parent ID found in the dataset?\n",
            "116. Question: What is the non-null third level value in the dataset that appears first?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117. Question: What is the name of the direct ascendant of the bars and restaurants entity?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118. Question: How many elements are there in our taxonomy?\n",
            "119. Question: How many elements in the taxonomy do not have a parent id associated?\n",
            "120. Question: What is the total number of unique non-null Parent values?\n",
            "121. Question: How many entries belong to the third or fourth tiers?\n",
            "122. Question: How many unique entries exist in the first level of our taxonomy?\n",
            "123. Question: How many rows contain null values in Tier 2?\n",
            "124. Question: How many Parent IDs appear exactly once?\n",
            "125. Question: Are all names unique?\n",
            "126. Question: What is the number of unique names?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127. Question: List the 3 Parent values associated the 3 highest number of descendants (direct or otherwise).\n",
            "128. Question: List the entry counts for the attractions and automotive entities.\n",
            "129. Question: List the number of children for the categories of commercial trucks and convertibles. Answer with a two element list.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130. Question: List counts of non-null values for each Tier column.\n",
            "131. Question: List the first (by number of appearance) 3 different values in the highest tier of the dataset. If there are less than 3 list as many as there are.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132. Question: List the first (by row number) 2 different level 1 values found in the dataset. If there are less than 2 list as many as there are.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133. Question: List the first (by number of appearance) 4 different second highest level values.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134. Question: List all (unique) highest tier values present in the first 4 rows.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135. Question: List the 4 first tier values present in the first 4 rows.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136. Question: List the first 4 different non-null parent values found in the dataset. If there are less than 4 list as many as there are.\n",
            "137. Question: List the first 3 different non-null parent values found in the dataset. If there are less than 3 list as many as there are.\n",
            "138. Question: Is there any vegan product in our dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139. Question: Did Eduardo create upload any products to the database?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140. Question: Is the product with code 00001522 apt for vegans?\n",
            "141. Question: Is any product palm oil free?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142. Question: Are there any products belonging to the category 'Plant-based foods and beverages'?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143. Question: Are all products created by the openfoodfacts contributors labeled as vegan?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144. Question:  Are more than a 1000 products sold in Mercadona stores?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145. Question: Are there products from the 'Hacendado' brand in more than one country?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146. Question: What is the most frequent brand name? Answer with a single category.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147. Question: Which country has the most products listed? Answer with a single category.\n",
            "148. Question: What is the single label associated with the most products? Answer with a single category.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149. Question: How many products are labeled as 'Vegan'?\n",
            "150. Question: Which store has the most products listed?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151. Question: Which creator has contributed the most to the database?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152. Question: How many products belong to the 'Hacendado' brand?\n",
            "153. Question: How many unique countries exist in the dataset?\n",
            "154. Question: How many products have no labels?\n",
            "155. Question: How many products are associated with the 'Mercadona' type of store?\n",
            "156. Question: What is the total number of products in the dataset that have a non-empty product name?\n",
            "157. Question: What is the total number of products in the dataset that have a unique product code?\n",
            "158. Question: How many products are listed under 'Plant-based foods and beverages'?\n",
            "159. Question:  List the product codes associated with the Seitan category\n",
            "160. Question:  List the product names associated with the Seitan category\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161. Question: List the two most frequent labels in the dataset\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162. Question:  \"List the five most frequent labels in the dataset. If there are less than five list as many as there are.\"\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163. Question:  List the two most frequent store names in the dataset\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164. Question:  List the two number of stores for the two most frequent store names in the dataset\n",
            "165. Question:  List the 3 most frequent countries in the dataset\n",
            "166. Question:  List the 3 number of products present for the 3 most frequent countries in the dataset\n",
            "167. Question: Is Switzerland the country with the highest Cost of Living Index?\n",
            "168. Question: Is the Bahamas ranked second in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169. Question: Is there any country with a Rent Index above 65?\n",
            "170. Question: Does Iceland have more purchasing power than a country that has a 100 in that index?\n",
            "171. Question: Is Barbados considered overall more expensive than the country ranked in the 10th place?\n",
            "172. Question: Does the dataset include at least 120 countries?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173. Question: If I am from Iceland and I move to Singapore, would I expect my rent to be more expensive according to the index?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174. Question: Is Switzerland considered to be the most expensive country regardless if I rent or own my home?\n",
            "175. Question: Which country ranks the most expensive in terms of overall cost of living?\n",
            "176. Question: In which country would it be cheaper to buy groceries?\n",
            "177. Question: If I have to rent but I want to move to the cheapest country to live in, where should I move to?\n",
            "178. Question: In which country would it be most expensive to eat in a restaurant?\n",
            "179. Question: Which country has the second-highest world rent?\n",
            "180. Question: Which country is the second most expensive destination to move to considering I am not a home owner in the country?\n",
            "181. Question: Which country has a Groceries Index closest to 80?\n",
            "182. Question: What is the Cost of Living Index assigned to the most expensive country to live in?\n",
            "183. Question: What is the Rent Index of the top-ranked country?\n",
            "184. Question: What is the total number of countries in the dataset?\n",
            "185. Question: What is the average Groceries Index across all countries?\n",
            "186. Question: What is the difference between the highest and lowest Restaurant Price Index?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187. Question: If I'm moving to Singapore and I have to rent there, what would my associated index for cost of living be?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188. Question: What is the mean Local Purchasing Power Index of the top 10 countries by rank?\n",
            "189. Question: What is Iceland's rank?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190. Question: List the Rent Index values of the top 5 overall most expensive countries excluding rent.\n",
            "191. Question: List the Cost of Living Index values of the 5 countries that are ranked the cheapest.\n",
            "192. Question: List the Local Purchasing Power Index values of countries ranked 1st to 5th.\n",
            "193. Question: List the 3 associated index values for the countries where groceries are most expensive.\n",
            "194. Question: List the index given to restaurant prices for the top 5 overall most expensive countries for home owners.\n",
            "195. Question: List the 5 lowest indices for cost of life for a person who have to rent.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196. Question: List the 5 Local Purchasing Power Index values closest to 100.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197. Question: List the names of the top 5 ranked countries.\n",
            "198. Question: List the 3 countries where I would pay the most for groceries.\n",
            "199. Question: List the 3 countries where it's cheapest to rent.\n",
            "200. Question: List the countries ranked 10th to 15th.\n",
            "201. Question: List the top 5 countries by Local Purchasing Power Index.\n",
            "202. Question: List the 3 countries where restaurants are the cheapest.\n",
            "203. Question: Is there any applicant who got a grade better than 330 in their graduate record examination?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204. Question: Is there any applicant who got a score worse than 100 in their English test?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205. Question: Is the best CGPA greater than 9.5?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206. Question: Did any applicant with a perfect university rating score get a grade below 320 in their graduate record examination?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207. Question: Is there an applicant with a chance above 95 per cent of getting into the university they applied to?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208. Question: Is the lowest score assigned to a student's stated purpose for admission worse than 2?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209. Question: Are there any applicants who don't have any research experience previous to their application?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210. Question: Is the average English score better than 105?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211. Question: What is the rating given by the college they applied to to the applicant with the highest CGPA?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212. Question: What is the university rating of the applicant with the lowest GRE score?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213. Question: Which score given to the stated purpose of admission of the student is most common among applications?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "214. Question: What is the score for the recommendation letters presented by the student with the lowest English score?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215. Question: What is the university rating of the applicant who is less likely to be admitted?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216. Question: Which rating given to the stated purpose of students is associated with the highest accumulated grade point average?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217. Question: Which rating number is most commonly given by universities?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218. Question: Do most students have some research experience prior to the application?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219. Question: What is the highest graduate record score in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220. Question: What is the average English score of applicants who have at least some research experience?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221. Question: What is the total number of applicants with a university rating of 3?\n",
            "222. Question: What is the maximum grade point average among applicants without research experience?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223. Question: What is the minimum score of letters presented among applicants who have over an eighty per cent chance of admission?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224. Question: What is the standard deviation of CGPA scores?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225. Question: What is the sum of English test scores for applicants with an stated purpose better than 4?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226. Question: How many applicants have a graduate record score between 300 and 310 (including both)?\n",
            "227. Question: List the 5 highest graduate record scores in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228. Question: How many people in the dataset got a perfect English score?\n",
            "229. Question: How many applicants got a perfect score in their statement of purpose?\n",
            "230. Question: List the top 5 English scores in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231. Question: List the 5 lowest grade point average scores in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232. Question: List the top 5 stated purpose scores in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233. Question: List the top 5 scores assigned to endorsement letters in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234. Question: List the top 5 English scores of applicants who have experience as researchers.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235. Question: List the best 2 graduate record scores of applicants whose stated motivation to enter got a rating better than 4.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236. Question: List the 2 worst grade point average scores of applicants who received the second worst possible rating from their university.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237. Question: List the university ratings associated with the top 5 CGPA scores.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238. Question: List the university ratings of the lowest 5 grade point average scores.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239. Question: List the scores given to the stated motivations of the 4 applicants who have the best shot at getting into the university they applied to.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240. Question: List the SOP ratings of applicants with the top 5 English scores.\n",
            "Processing table with 1 chunks (chunk size: 20)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241. Question: List the LOR ratings of applicants with the lowest 5 gpa scores.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "242. Question: Is there any individual in the dataset with a body mass index greater than 50?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "243. Question: Is it true that the number of regions represented are more than 3?\n",
            "244. Question: Is it true that there are no centenarians in this dataset? \n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245. Question: Is the average BMI found in this dataset considered not to be obese?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "246. Question: Are there any childless individuals?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247. Question: Does the dataset contain people who do not consume tobacco?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "248. Question: Is there anyone that is a northeastern?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "249. Question: Would an individual with the median BMI of the dataset considered to be underweight?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250. Question: Is the maximum medical charge in the dataset greater than $60,000?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251. Question: What is the location most represented in this dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252. Question: Which gender has the highest number of individuals?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "253. Question: What is the smoking status of the individual who paid the most money?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254. Question: What is the region the youngest teenager comes from?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255. Question: What is the gender of the person with the highest body mass index?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256. Question: Is being childless the most common state for people in the dataset? True\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257. Question: What is the most frequent number of children?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "258. Question: What region is represented least in the dataset?\n",
            "259. Question: What is the smoking status of the individual with the lowest BMI?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260. Question: What is the maximum BMI in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261. Question: What is the average number of children?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262. Question: How many unique regions are in the dataset?\n",
            "263. Question: What is the sum of all medically related charges in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264. Question: How old is the youngest teenager in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265. Question: How many people in the dataset have lived for more than six decades?\n",
            "266. Question: How many people could be considered smokers?\n",
            "267. Question: What is the median BMI in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268. Question: List the 2 highest BMIs in the dataset for people who can be considered to suffer from Class III Obesity.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269. Question: List the charges of individuals with the 3 highest BMIs.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270. Question: List the ages of individuals with the 5 lowest charges.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271. Question: List the ages of the 3 youngest teenagers.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272. Question: List the unique different smoking statuses found among individuals over 60 years of age.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273. Question: List the regions of individuals with the 3 highest BMIs.\n",
            "274. Question: Is there a lifter older than 50?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275. Question: Does the dataset contain squatting lifts?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276. Question: Is the biggest lift performed greater than 880 pounds?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277. Question: Is the minimum lifted less than 330 pounds?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 30.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278. Question: Are there more than 100 lifters in the weight class someone that weights 82kg would compete in?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "279. Question: Is the average age of all lifting records in the '105 kg' weight class above 40?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 31.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280. Question: Is the average age of all lifting records in the weight class of someone who weights 103000 grams above 40?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281. Question: Does 'Jessica Wilson' appear in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282. Question: Are there fewer than 5 unique types of exercise recorded?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "283. Question: Which weight class has the best average lifted weight?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "284. Question: What is the most common 'Weight Class'?\n",
            "285. Question: Which type of exercise has the best average lift?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "286. Question: What is the current record in kilograms for maximum weight ever lifted'?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "287. Question: How many different athletes are there in the dataset?\n",
            "288. Question: How many different men can we find in this dataset?\n",
            "289. Question: How many different women are there in the dataset?\n",
            "290. Question: What's the highest record set by men in the bench press category?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291. Question: What's the best record set by women in the bench press category?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "292. Question: Who is the woman with the best lifting record?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "293. Question: What is the total sum of the amounts lifted in a bench press exercise?\n",
            "294. Question: What is the least amount of kilos lifted in the weight class that someone who is 55kg would participate in?\n",
            "295. Question: What is the difference betweent the highest amount lifted and the lowest?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "296. Question: How many lifters are in the weight class that people who weight 139 pounds would enter?\n",
            "297. Question: What are the highest 3 amounts ever lifted by anyone?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298. Question: List the 5 smallest amounts ever lifted by anyone.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299. Question: What are the top 5 total lifts by 'Weight Class'?\n",
            "300. Question: What are the 3 largest age gaps present between lifts for each weight class?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301. Question: List the 2 worst lifts in the '105 kg' weight class.\n",
            "302. Question: List the top 3 amounts lifted while squatting.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303. Question: List the 5 names of the women lifting in this dataset"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304. Question: List the 5 men names of men who perform exercises in this dataset\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305. Question: What are the top 3 'Weight Classes' by total lifts?\n",
            "306. Question: List 5 lifters from the '74 kg' weight class.\n",
            "307. Question: What are the 3 least frequent types of exercise we find in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308. Question: What are the 3 most frequent types of exercise we find in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309. Question: Is there any condition where the mortality rate is more prevalent than a condition with a rate of 300?"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310. Question: Are there more cases recorded in cities overall?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311. Question: Is the maximum mortality rate in the dataset worse than 250?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312. Question: Does the dataset include any case with an error less than 0.5?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313. Question: Are all values associated with the death rate higher than 100?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 28.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314. Question: Are all of the most frequent causes of mortality related to the heart?\n",
            "315. Question: Does any region appear more than 50 times?\n",
            "316. Question: Are there more cases recorded for men than for women?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317. Question: What is the region with the most deaths per capita?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "318. Question: What cause corresponds to the lowest mortality rate?\n",
            "319. Question: What gender has the worst average mortality rate?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320. Question: What is the type of status with the best average ratio?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321. Question: What region has the worst average rate?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 27.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322. Question: What is the maximum value in the ratio column?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323. Question: What is the minimum error present in this dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324. Question: How many cases have a death rate worse than 200?\n",
            "325. Question: What is the total sum of all death rate values?\n",
            "326. Question: What is the average error recorded?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327. Question: What is the standard deviation of ratio?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328. Question: How many distinct HHS regions are present?\n",
            "329. Question: What is the range (max-min) that death rates for any cause of death appearing in this dataset can take?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 29.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330. Question: What are the 5 worst death rates recorded?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331. Question: What are the lowest 5 values for error deviations recorded for the rates?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "332. Question: List the 5 smallest ratio values that are still greater than 100.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333. Question: List the highest 4 deviations recorded to the expected rate recorded in urban areas.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334. Question: List the 5 smallest deviations from the expected death rate in relation to diseases of the heart.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335. Question: List the unique causes for death found in the first region of the United States Department of Health and Human Services.\n",
            "336. Question: What are the 3 regions with the worst average mortality rate?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "337. Question: What are the 2 categories present in the dataset that discriminate if a case happened in a city-like environment or not?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338. Question: Is there a player with exactly a thousand total points in a given season? Answer True or False\n",
            "339. Question: Is there a season where any player scored more than 3000 points? Answer True or False\n",
            "340. Question: Did any player not miss any free throws in a single season? Answer True or False \n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "341. Question: Is there a team that had a player scoring exactly 2k points in one season? Answer True or False\n",
            "342. Question: Is there any player with a number of rebounds better than 500 in a single season? Answer True or False\n",
            "343. Question: Did any player ever achieve more than 500 assists in one season? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344. Question: Did any player play in every game of a season? Answer True or False\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345. Question: Is there any player with a field goal record for a given season/playoffs better than 9/10?\n",
            "346. Question: Which player scored the most points in the season that finished in 2013?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 18.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347. Question: Which player scored the most points in the season that started in 2012?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348. Question: Which team had the highest total points scored by its players?\n",
            "349. Question: What is the player name with the highest yet non-perfect free throw performance in the 2012-2013 year?\n",
            "350. Question: Which team had the most rebounds?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "351. Question: Who led in assists in the regular season that started in 2012?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352. Question: Which player had the most steals in a given season?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 23.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353. Question: What is the highest number of steals in a given season?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 17.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354. Question: What is the total number of rebounds recorded in the dataset?\n",
            "355. Question: What is the total number of rebounds recorded in the dataset where the ball didn't change possession?\n",
            "356. Question: In what percentage of the rebounds recorded in the dataset did the ball remain on the same team? Answer with a number\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 21.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "357. Question: How many games did the player with the most minutes played in a single season play in that season?\n",
            "358. Question: What is the record set for single-season assists within the dataset?\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359. Question: How many players played in the 2010-11 season?\n",
            "360. Question: How many players scored exactly 2000 points in a season?\n",
            "361. Question: What was the highest number of blocks by any player in a season?\n",
            "Error in direct query processing: Categorical is not ordered for operation max\n",
            "you can use .as_ordered() to change the Categorical to an ordered one\n",
            "\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "362. Question: List the three highest rebound totals by a single player in one season.\n",
            "363. Question: What are the three highest total assist values in one season?\n",
            "364. Question: List the top 4 total point achieved by a single player in one season.\n",
            "365. Question: List the three highest numbers of steals.\n",
            "Processing table with 2 chunks (chunk size: 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 22.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366. Question: List the top 3 block counts in the dataset.\n",
            "367. Question: List the 5 players with the least games played.\n",
            "368. Question: List the three players with the most rebounds.\n",
            "369. Question: List the top 5 of teams with the highest total points overall.\n",
            "370. Question: List the top 5 of teams with the highest total rebounds overall.\n",
            "371. Question: List the 2 players with the most steals overall.\n",
            "372. Question: List the three players with the highest blocks in a single season.\n",
            "373. Question: List the top 4 players by assists in a single given season.\n",
            "374. Question: Is there any woman in the dataset with a BMI greater than 30?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375. Question: Is there any woman younger than 18 years?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "376. Question: Does the dataset contain any woman who has never been pregnant?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "377. Question: Are all women in the dataset younger than 40 years?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378. Question: Does every woman in the dataset have an associated height strictly greater than 1.40 meters?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "379. Question: Is there at least one woman with heredity marked positively?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380. Question: Are all women in the dataset predicted to be free of diabetes? (to have diabetes is associated with the positive label of the model)\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381. Question: How many teen pregnancies are there in this dataset?\n",
            "382. Question: Is there a woman with a weight of exactly 50000 grams?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383. Question: What is the most value of the status marking hereditary diabetes risk in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384. Question: What is the age of the woman with the lowest body mass index?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385. Question: What is the maximum height amongst the two heaviest women?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386. Question: Which number of pregnancies is most common?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "387. Question: What is the most frequent BMI value in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388. Question: How much does the heaviest person in the dataset weight?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389. Question: How tall is the shortest person in the dataset? Answer with the number of meters.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390. Question: What is the average BMI across all women?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391. Question: What is the total number of women in the dataset?\n",
            "392. Question: What is the median age of women in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "393. Question: How many women weight less than 60 kg?\n",
            "394. Question: What is the range (max-min) of the different heights in meters? Answer with a single number\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "395. Question: What is the standard deviation found among the BMIs?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396. Question: List the 3 heights of the 3 tallest women in the dataset (in cm).\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "397. Question: List the different ages (in years) of teenagers found in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 26.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "398. Question: Provide a list with the unique reported pregnancy numbers of women weighing more (>) than 70000g. If there are none answer with an empty list.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "399. Question: List the weights of women with a height of exactly 1m and 45cm.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400. Question: List the different labels assigned to heredity statuses.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 22.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401. Question: List the different prediction outcomes for diabetes found in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402. Question: List the unique height values (converted to cm) found among of women with a BMI<18.5.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 25.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403. Question: List the unique pregnancy numbers of women older than 30 years. If there are none answer with an empty list.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 24.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404. Question: List the unique ages of the youngest five women who have a diabetes risk associated with their family. If there are less than five answer with all the unique ages that match the criteria.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "405. Question: Is there any record where the area affected is greater than 50ha?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "406. Question: Was there any fire unaffected by wind?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "407. Question: Is the maximum value of 'DMC' less than 200?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "408. Question: Are all of the horizontal axis coordinates plotted to the right of the third column?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "409. Question: Are there any entries where the temperature is below freezing level in Celsius?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410. Question: Is there any measuring that recorded 0% humidity ?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "411. Question: Are there more than 10 unique months in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "412. Question: Are all months of the year present in the dataset?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "413. Question: Is the average value of wind speed recorded faster than 3?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "414. Question: If the year starts in January, what is the numeric id of the worst month in terms of number of fires?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "415. Question: Answer with the numeric ID of the day of the week the hottest temperature was recorded\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416. Question: What is the name of the month that recorded the driest day when a fire took place?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "417. Question: What is the label id of the month with the largest area burned?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "418. Question: What is the name of the windiest day on average?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "419. Question: What is the name of the month with the smallest average 'DC' value?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420. Question: Which month number corresponds to the highest average 'ISI' value?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "421. Question: Which day was the minimum 'DMC' value recorded? Answer with the day's name\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422. Question: What is the hottest temperature recorded?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 18.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "423. Question: What is the speed of the slowest wind in our records?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "424. Question: Assuming fires are always in different terrain, what is the total added area affected by fires in the dataset?\n",
            "425. Question: How many unique values are there in the vertical axis column?\n",
            "426. Question: What is the mean percentage of relative humidity? Answer with a number\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "427. Question: What is the range (max - min) of 'DC' values?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428. Question: What is the standard deviation of the 'ISI' column?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429. Question: How many fires affected a negligible (zero) amount of terrain?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430. Question: What are the 3 hottest temperatures recorded?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "431. Question: List the 5 smallest values in the 'DC' column.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "432. Question: Provide the unique values in the vertical axis of the associated graph from bottom to top.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "433. Question: What are the 4 recorded humidity percentages of the 4 driest records?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "434. Question: List the 5 (can be repeated) highest wind speeds recorded.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435. Question: Provide the size of the top 3 greatest areas a fire affected.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436. Question: List the minimum 3 'DMC' values in ascending order.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "437. Question: List the unique full month names when fires were recorded in ascending order.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438. Question: Provide the 3 names of the days when fires were most frequently recorded. \n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "439. Question: What are the 2 full names of the 2 months the first 2 rows of the database took place in?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440. Question: Provide the name of the days when the 3 highest temperatures were recorded. \n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "441. Question: List the unique month names corresponding to the driest 4 percentages of RH.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "442. Question: Provide the unique day names associated with the highest 5 'DMC' values.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "443. Question: List the unique full names of the days where wind speed has been faster than 5mph.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "444. Question:  Is there a transaction where more than 10 products were sold?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "445. Question:  Is 99 an existing id for a store?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "446. Question:  Do all rows of this dataset have a different product id?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "447. Question: Did we ever sell 20 items in the same transaction?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448. Question: Is there any single product with a price greater than 100?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449. Question: Does the dataset have fewer than 200k rows?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450. Question: Do we have a separate category for drinking chocolate in our stores?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451. Question: Is 5 the ID of the store with the most transactions?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "452. Question: What is the location of our most popular store?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "453. Question: Which category is associated with the smallest single product price in the database?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "454. Question: Which are the first three letters of day of the week which has worst performance in terms of revenue?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455. Question: What is the product type of the transactions with yielded the most money in revenue? Answer with a category.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456. Question: What are the first three letters of the month that has the highest average products per transaction?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "457. Question: Which hour has the lowest number of transactions? Answer with a number from 0 to 23.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "458. Question: What is the location of the first purchase row-wise?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "459. Question: What is the categorization of the first product row-wise?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "460. Question: What is the maximum amount of products that were sold in a single given transaction?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "461. Question: How many unique different products do we sell?\n",
            "462. Question: What is the total revenue provided by all the transactions in the dataset?\n",
            "463. Question: Are our stores open on Sunday?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "464. Question: What is the average unitary price in our transactions?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "465. Question: What is the total number of transactions carried on a Sunday?\n",
            "466. Question: How many active stores do we own according to this dataset?\n",
            "467. Question: How much revenue did our best single transaction bring?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468. Question: How many transactions occurred in the sixth month of the year?\n",
            "469. Question: List the 3 largest amount of products bought in one transaction? If there are less than 3 list as many as there are.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470. Question: List the different store ids\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "471. Question: List the lowest 4 single-product price values\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "472. Question: List highest 3 different revenues a given transaction has yielded?\n",
            "473. Question: List the unique numerical weekly values present in this dataset\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "474. Question: What are the different locations where our business is present?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "475. Question: What are the unique product_category names in transactions with transaction_qty > 5? If there are none answer with an empty list\n",
            "476. Question: What are the 3 most common product_type names?\n",
            "477. Question: What are the abbreviated month names where transactions have been present?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "478. Question: Could you list the unique weekday names our transactions are recorded in?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "479. Question:  List the IDs of our 2 most popular stores in terms of number of purchases\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "480. Question:  What are the 2 (non-unique) product types associated with the highest 2 revenues of a single given purchase? Answer with a list with 2 elements.\n",
            "481. Question:  What is the name of the animal involved in the production of the most expensive coffee-related product that we offer? Answer with a value present in a cell of the database.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "482. Question: Do we have any book on sale? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "483. Question: Are there any books that are longer than 500 pages? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "484. Question: Did Mr Harari write a book on history? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485. Question: Does any book have a rating better than 35? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "486. Question: Do we still have enough stock of all books? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487. Question: A customer asked for a book titled 'The greatest book to ever exist', do we have it in stock? Answer True or False\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "488. Question: Is there any book published by Harper Collins for India?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489. Question: Are there any books with fewer than 100 pages?"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490. Question: Which book is considered the best by our clients?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491. Question: Assuming all books are similar in reading difficulty, which category does the book that would take longest to read belong to?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "492. Question: How many suns were there in the title of Hosseinis' novel? Answer with a number\n",
            "493. Question: How many books are written by multiple authors? (explicitly mentioned translators and editors count as authors)\n",
            "494. Question: Who was the book with most reviewed book written by?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "495. Question: If I wanted to buy the shortest book, how long would be the book that I'd pick?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "496. Question: What is the publisher of the nineteenth edition of Let Us C?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497. Question: How much stock (in number of books) of Ben Graham's work is there in this store?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498. Question: Which category does the Quran belong to?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "499. Question: According to this database, how many editions has 'The Intelligent Investor' gone through?\n",
            "500. Question: What is the total number of book pages in our database?\n",
            "501. Question: If I can read 200 pages a day and I want to pick a book that I can read in half a day, what is the number of books that I can choose from?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502. Question: What is the average rating of all books?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "503. Question: If we had 30 copies of the arabic reader this morning, how many have we sold?\n",
            "504. Question: How many pages does Sapiens have?\n",
            "505. Question: How many books could be said to fall in the islamic category?\n",
            "506. Question: How many books have been reviewed more than 10 times?\n",
            "507. Question: What is the total number of books that we are selling below their usual price?\n",
            "508. Question: List the page counts of the first five books in the dataset?\n",
            "509. Question: List the page lengths (in numeric form) of the first five books?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510. Question: List the ratings of the top four books with the most reviews?\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511. Question: Provide me with a list containing all the lengths of the books about computer science.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512. Question: List the number of copies left for the first five books.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513. Question: List the ratings of the last five books in the dataset\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "514. Question: List the page counts of books in the 'History and Tradition' category?\n",
            "515. Question: What is the stock of the book that is closest to running out copies but hasn't yet?.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "516. Question: List the categories of the first five books.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "517. Question: List the authors of books that are not on sale today.\n",
            "518. Question: List the titles of books with fewer than 200 pages.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "519. Question: List the categories of books with ratings above 20.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "520. Question: List the authors of books with more than 10 reviews.\n",
            "521. Question: List the 5 categories of the last five books in the dataset.\n",
            "Processing table with 1 chunks (chunk size: 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "522. Question: List the editions of books in the 'Business, Investment and Economics' category.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwnwkIei5fsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erpsJanw8nY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQSMRLvtNe5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_7cNZPBiBqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKrwZeOTUUXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pE2R9lSgUnAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXqcZi7kX1ip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}